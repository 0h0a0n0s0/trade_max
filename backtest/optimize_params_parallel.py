# optimize_params_parallel.py
"""
ä¸¦è¡Œç‰ˆæœ¬çš„åƒæ•¸å„ªåŒ–è…³æœ¬ï¼ˆé‡å° Mac M1 å„ªåŒ–ï¼‰
ä½¿ç”¨ multiprocessing å¯¦ç¾çœŸæ­£çš„ä¸¦è¡ŒåŸ·è¡Œ
"""
import argparse
import csv
import logging
import random
from decimal import Decimal
from pathlib import Path
from typing import Dict, List, Optional
from multiprocessing import Pool, Manager
import pandas as pd
import yaml
import time

import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥ GridStrategy
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# å˜—è©¦å…©ç¨®å°å…¥æ–¹å¼ï¼ˆæ”¯æŒå¾æ ¹ç›®éŒ„æˆ– backtest ç›®éŒ„é‹è¡Œï¼‰
try:
    from backtest.backtest_adapter import BacktestAdapter
except ImportError:
    from backtest_adapter import BacktestAdapter

from strategy_usdttwd_grid_refactored import GridStrategy

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
LOG = logging.getLogger("ParamOptimizerParallel")


def run_single_backtest(args_tuple):
    """å–®å€‹å›æ¸¬ä»»å‹™ï¼ˆç”¨æ–¼å¤šé€²ç¨‹ï¼‰- ä½¿ç”¨ BacktestAdapter ç¢ºä¿é‚è¼¯ä¸€è‡´æ€§"""
    params, init_usdt, init_twd, csv_path = args_tuple
    
    try:
        # åœ¨æ¯å€‹é€²ç¨‹ä¸­é‡æ–°è¼‰å…¥æ•¸æ“šï¼ˆé¿å…åºåˆ—åŒ–å•é¡Œï¼‰
        temp_df = pd.read_csv(csv_path, usecols=['ts', 'high', 'low', 'close'])
        
        # Handle timestamp
        if pd.api.types.is_numeric_dtype(temp_df['ts']):
            try:
                tss = pd.to_datetime(temp_df['ts'], unit='ms')
                if tss.min().year < 2000:
                    raise ValueError("ts likely in seconds, not milliseconds.")
            except (ValueError, pd.errors.OutOfBoundsDatetime):
                tss = pd.to_datetime(temp_df['ts'], unit='s')
            temp_df['ts'] = tss
        else:
            temp_df['ts'] = pd.to_datetime(temp_df['ts'])
        
        price_df = temp_df.set_index('ts')
        price_df['high'] = price_df['high'].astype(float)
        price_df['low'] = price_df['low'].astype(float)
        price_df['close'] = price_df['close'].astype(float)
        price_df.ffill(inplace=True)
        
        # ä½¿ç”¨ BacktestAdapter å’Œ GridStrategyï¼ˆèˆ‡å¯¦ç›¤ç›¸åŒçš„é‚è¼¯ï¼‰
        strategy = GridStrategy(params)
        adapter = BacktestAdapter(
            strategy=strategy,
            init_usdt=Decimal(str(init_usdt)),
            init_twd=Decimal(str(init_twd)),
            fee_rate=Decimal(str(params.get('taker_fee', '0.0004'))),
            verbose=False
        )
        
        stats = adapter.run(price_df)
        
        # è¨ˆç®— Robustness Scoreï¼ˆç©©å¥æ€§åˆ†æ•¸ï¼‰
        # Formula: score = roi_pct * 0.4 + (100 / (max_drawdown_pct + 1)) * 0.6
        roi_pct = stats['roi_pct']
        max_dd_pct = stats['max_drawdown_pct']
        robustness_score = roi_pct * 0.4 + (100 / (max_dd_pct + 1)) * 0.6
        
        stats['robustness_score'] = robustness_score
        
        # ä½¿ç”¨ Robustness Score å’ŒåŸºæœ¬é–¾å€¼é€²è¡Œç¯©é¸
        # è¦æ±‚ï¼šROI > 0.5%, MaxDD < 15%, Robustness Score > 10
        if stats['roi_pct'] > 0.5 and stats['max_drawdown_pct'] < 15.0 and robustness_score > 10.0:
            return {
                'params': params,
                'stats': stats,
                'success': True
            }
    except Exception as e:
        LOG.warning(f"Backtest failed: {e}")
        import traceback
        traceback.print_exc()
    
    return {'success': False}


class ParameterOptimizerParallel:
    """ä¸¦è¡Œç‰ˆæœ¬çš„åƒæ•¸å„ªåŒ–å™¨"""
    
    def __init__(self, csv_path: Path, base_config_path: Path, 
                 init_usdt: float = 10000.0, init_twd: float = 300000.0,
                 num_workers: int = 4):
        self.csv_path = csv_path
        self.base_config_path = base_config_path
        self.init_usdt = Decimal(str(init_usdt))
        self.init_twd = Decimal(str(init_twd))
        self.num_workers = num_workers
        self.base_config = {}
        self.price_df = None
        self.valid_results = []
        self.iteration_count = 0
        self.max_iterations = 2000
        self.target_valid_sets = 100
        
        self._load_data()
        self._load_base_config()
    
    def _load_data(self):
        """Load OHLC data from CSV"""
        print(f"ğŸ“‚ è¼‰å…¥æ•¸æ“š: {self.csv_path.name}...")
        try:
            temp_df = pd.read_csv(self.csv_path, usecols=['ts', 'high', 'low', 'close'])
            
            # Handle timestamp
            if pd.api.types.is_numeric_dtype(temp_df['ts']):
                try:
                    tss = pd.to_datetime(temp_df['ts'], unit='ms')
                    if tss.min().year < 2000:
                        raise ValueError("ts likely in seconds, not milliseconds.")
                except (ValueError, pd.errors.OutOfBoundsDatetime):
                    LOG.warning("Could not parse ts as milliseconds, trying seconds...")
                    tss = pd.to_datetime(temp_df['ts'], unit='s')
                temp_df['ts'] = tss
            else:
                temp_df['ts'] = pd.to_datetime(temp_df['ts'])
            
            self.price_df = temp_df.set_index('ts')
            self.price_df['high'] = self.price_df['high'].astype(float)
            self.price_df['low'] = self.price_df['low'].astype(float)
            self.price_df['close'] = self.price_df['close'].astype(float)
            self.price_df.ffill(inplace=True)
            
            print(f"   âœ“ æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(self.price_df):,} æ ¹Kç·š")
        except Exception as e:
            LOG.error(f"Failed to load data: {e}", exc_info=True)
            raise
    
    def _load_base_config(self):
        """Load base configuration"""
        try:
            with open(self.base_config_path, 'r', encoding='utf-8') as f:
                self.base_config = yaml.safe_load(f) or {}
            # Config loaded silently
        except Exception as e:
            LOG.error(f"Failed to load base config: {e}", exc_info=True)
            raise
    
    def _generate_random_params(self) -> Dict:
        """Generate a random set of parameters within defined ranges"""
        params = self.base_config.copy()
        
        # æ–¹å‘1å„ªåŒ–ï¼šé‡é»å„ªåŒ–è¶¨å‹¢è·Ÿéš¨åƒæ•¸ï¼Œç¶²æ ¼ä½œç‚ºè¼”åŠ©
        # ç­–ç•¥èª¿æ•´ï¼šå®Œå…¨è½‰å‘è¶¨å‹¢è·Ÿéš¨ï¼Œç¶²æ ¼ä½œç‚ºè¼”åŠ©
        
        # ATRå‹•æ…‹ç¶²æ ¼ä¹˜æ•¸ï¼ˆç¶²æ ¼ä½œç‚ºè¼”åŠ©ï¼Œé–“è·å¯ä»¥ç¨å¤§ï¼‰
        if params.get('use_atr_spacing', False):
            params['atr_spacing_multiplier'] = str(round(random.uniform(0.5, 1.5), 3))  # 0.5-1.5ï¼ˆç¶²æ ¼ä½œç‚ºè¼”åŠ©ï¼‰
        
        # ç¶²æ ¼å€æ•¸ï¼ˆå½±éŸ¿ç¶²æ ¼å±¤ç´šé–“è·ï¼‰
        params['mid_mult'] = random.randint(2, 5)  # æ“´å¤§ï¼š2-5
        params['big_mult'] = random.randint(5, 12)  # æ“´å¤§ï¼š5-12
        
        # è¨‚å–®å¤§å°ï¼ˆå½±éŸ¿è³‡é‡‘åˆ©ç”¨ç‡å’Œå–®ç­†åˆ©æ½¤ï¼‰
        # æ‰¾åˆ°çš„æœ‰æ•ˆåƒæ•¸åœ¨0.029-0.068ï¼Œéœ€è¦æé«˜ä»¥å¢åŠ æ”¶ç›Š
        params['size_pct_small'] = str(round(random.uniform(0.03, 0.08), 4))  # æé«˜ï¼š0.03-0.08
        params['size_pct_mid'] = str(round(random.uniform(0.04, 0.10), 4))  # æé«˜ï¼š0.04-0.10
        params['size_pct_big'] = str(round(random.uniform(0.05, 0.12), 4))  # æé«˜ï¼š0.05-0.12
        
        # EMAåƒæ•¸ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–ï¼šèª¿æ•´è‡³æ¥­ç•Œæ¨™æº–ï¼‰
        # æ¥­ç•Œæ¨™æº–ï¼šå¿«ç·š12-50ï¼Œæ…¢ç·š26-200
        params['ema_span_fast_bars'] = random.randint(12, 50)  # æ¥­ç•Œæ¨™æº–ï¼š12-50
        params['ema_span_slow_bars'] = random.randint(26, 200)  # æ¥­ç•Œæ¨™æº–ï¼š26-200
        
        # è¶¨å‹¢åå¥½ï¼ˆå½±éŸ¿å€‰ä½åˆ†é…ï¼‰
        params['bias_high'] = str(round(random.uniform(0.50, 0.80), 3))  # æ“´å¤§ï¼š0.50-0.80
        params['bias_low'] = str(round(random.uniform(0.10, 0.45), 3))  # æ“´å¤§ï¼š0.10-0.45
        params['bias_neutral_target'] = str(round(random.uniform(0.35, 0.60), 3))  # æ“´å¤§ï¼š0.35-0.60
        
        # small_gapä¿ç•™ä½œç‚ºå‚™é¸ï¼ˆå¦‚æœç¦ç”¨ATRå‹•æ…‹ç¶²æ ¼ï¼‰
        params['small_gap'] = str(round(random.uniform(0.001, 0.01), 4))  # 0.001-0.01
        
        # Ensure required parameters
        if 'macd_fast_period' not in params:
            params['macd_fast_period'] = 12
        if 'macd_slow_period' not in params:
            params['macd_slow_period'] = 26
        if 'macd_signal_period' not in params:
            params['macd_signal_period'] = 9
        if 'dmi_period' not in params:
            params['dmi_period'] = 14
        if 'grid_aggression_threshold' not in params:
            params['grid_aggression_threshold'] = 20
        if 'grid_aggression_multiplier' not in params:
            params['grid_aggression_multiplier'] = '1.0'
        if 'use_hybrid_model' not in params:
            params['use_hybrid_model'] = True  # å•Ÿç”¨æ··åˆæ¨¡å¼
        if 'use_atr_spacing' not in params:
            params['use_atr_spacing'] = True  # å•Ÿç”¨ATRå‹•æ…‹ç¶²æ ¼
        if 'use_adx_filter' not in params:
            params['use_adx_filter'] = False  # æ–¹å‘1å„ªåŒ–ï¼šç¦ç”¨ADXéæ¿¾å™¨ï¼Œä¸»è¦ä¾é è¶¨å‹¢è·Ÿéš¨
        if 'atr_spacing_multiplier' not in params:
            params['atr_spacing_multiplier'] = str(round(random.uniform(0.3, 1.5), 3))
        
        return params
    
    def _mutate_params(self, base_params: Dict, mutation_rate: float = 0.1) -> Dict:
        """Create a mutated variant of parameters"""
        params = base_params.copy()
        
        if 'small_gap' in params:
            val = float(params['small_gap'])
            params['small_gap'] = str(round(max(0.01, min(0.10, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'size_pct_small' in params:
            val = float(params['size_pct_small'])
            params['size_pct_small'] = str(round(max(0.03, min(0.08, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'size_pct_mid' in params:
            val = float(params['size_pct_mid'])
            params['size_pct_mid'] = str(round(max(0.04, min(0.10, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'size_pct_big' in params:
            val = float(params['size_pct_big'])
            params['size_pct_big'] = str(round(max(0.05, min(0.12, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'mid_mult' in params:
            params['mid_mult'] = max(2, min(5, params['mid_mult'] + random.randint(-1, 1)))
        
        if 'big_mult' in params:
            params['big_mult'] = max(5, min(12, params['big_mult'] + random.randint(-1, 1)))
        
        if 'ema_span_fast_bars' in params:
            change = int(params['ema_span_fast_bars'] * mutation_rate)
            params['ema_span_fast_bars'] = max(100, min(600, params['ema_span_fast_bars'] + random.randint(-change, change)))
        
        if 'ema_span_slow_bars' in params:
            change = int(params['ema_span_slow_bars'] * mutation_rate)
            params['ema_span_slow_bars'] = max(300, min(2000, params['ema_span_slow_bars'] + random.randint(-change, change)))
        
        # è¶¨å‹¢è·Ÿéš¨å€‰ä½æ¯”ä¾‹è®Šç•°
        if 'trend_trade_equity_pct' in params:
            val = float(params['trend_trade_equity_pct'])
            params['trend_trade_equity_pct'] = str(round(max(0.6, min(0.85, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        # ADXè¶¨å‹¢é€²å ´é–€æª»è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–ï¼šé€²ä¸€æ­¥é™ä½ï¼‰
        if 'adx_strength_threshold' in params:
            params['adx_strength_threshold'] = max(6, min(12, params['adx_strength_threshold'] + random.randint(-1, 1)))
        
        # å¤šæŒ‡æ¨™è¤‡åˆåˆ¤æ–·åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–ï¼šèª¿æ•´è‡³æ¥­ç•Œæ¨™æº–ï¼‰
        if 'rsi_period' in params:
            params['rsi_period'] = max(14, min(21, params['rsi_period'] + random.randint(-2, 2)))  # æ¥­ç•Œæ¨™æº–ï¼š14-21
        if 'rsi_bull_threshold' in params:
            val = float(params['rsi_bull_threshold'])
            params['rsi_bull_threshold'] = round(max(50.0, min(60.0, val + random.uniform(-2.0, 2.0))), 1)  # æ¥­ç•Œæ¨™æº–ï¼š50-60
        if 'rsi_bear_threshold' in params:
            val = float(params['rsi_bear_threshold'])
            params['rsi_bear_threshold'] = round(max(40.0, min(50.0, val + random.uniform(-2.0, 2.0))), 1)  # æ¥­ç•Œæ¨™æº–ï¼š40-50
        if 'adx_min_threshold' in params:
            params['adx_min_threshold'] = max(5, min(10, params['adx_min_threshold'] + random.randint(-1, 1)))  # æ¥µåº¦æ”¾å¯¬ï¼š5-10
        # å¸ƒæ—å¸¶åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–æ–°å¢ï¼‰
        if 'bollinger_window' in params:
            params['bollinger_window'] = max(18, min(22, params['bollinger_window'] + random.randint(-1, 1)))
        if 'bollinger_k' in params:
            val = float(params['bollinger_k'])
            params['bollinger_k'] = round(max(1.8, min(2.2, val + random.uniform(-0.1, 0.1))), 1)
        if 'bollinger_band_threshold' in params:
            val = float(params['bollinger_band_threshold'])
            params['bollinger_band_threshold'] = round(max(0.05, min(0.15, val + random.uniform(-0.02, 0.02))), 2)
        # éš¨æ©Ÿéœ‡ç›ªæŒ‡æ¨™åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–æ–°å¢ï¼‰
        if 'stochastic_k_period' in params:
            params['stochastic_k_period'] = max(12, min(16, params['stochastic_k_period'] + random.randint(-1, 1)))
        if 'stochastic_d_period' in params:
            params['stochastic_d_period'] = max(2, min(4, params['stochastic_d_period'] + random.randint(-1, 1)))
        if 'stochastic_oversold' in params:
            val = float(params['stochastic_oversold'])
            params['stochastic_oversold'] = round(max(25.0, min(35.0, val + random.uniform(-2.0, 2.0))), 1)
        if 'stochastic_overbought' in params:
            val = float(params['stochastic_overbought'])
            params['stochastic_overbought'] = round(max(65.0, min(75.0, val + random.uniform(-2.0, 2.0))), 1)
        
        # ATRå‹•æ…‹ç¶²æ ¼ä¹˜æ•¸è®Šç•°
        if 'atr_spacing_multiplier' in params:
            val = float(params['atr_spacing_multiplier'])
            params['atr_spacing_multiplier'] = str(round(max(0.3, min(1.5, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        # ç¶²æ ¼å±¤ç´šæ•¸é‡è®Šç•°
        if 'levels_each' in params:
            params['levels_each'] = max(16, min(24, params['levels_each'] + random.randint(-2, 2)))
        
        if 'bias_high' in params:
            val = float(params['bias_high'])
            params['bias_high'] = str(round(max(0.50, min(0.80, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        if 'bias_low' in params:
            val = float(params['bias_low'])
            params['bias_low'] = str(round(max(0.10, min(0.45, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        if 'bias_neutral_target' in params:
            val = float(params['bias_neutral_target'])
            params['bias_neutral_target'] = str(round(max(0.35, min(0.60, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        return params
    
    def optimize(self):
        """Run parallel optimization"""
        print("=" * 80)
        print("ğŸš€ åƒæ•¸å„ªåŒ–é–‹å§‹")
        print(f"   å·¥ä½œé€²ç¨‹æ•¸: {self.num_workers}")
        print(f"   ç›®æ¨™æœ‰æ•ˆåƒæ•¸çµ„æ•¸: {self.target_valid_sets}")
        print(f"   æœ€å¤§è¿­ä»£æ¬¡æ•¸: {self.max_iterations}")
        print(f"   ç¯©é¸æ¢ä»¶: ROI > 0.5% AND Max Drawdown < 15% AND Robustness Score > 10")
        print("=" * 80)
        
        start_time = time.time()
        batch_size = self.num_workers * 2  # Process in batches
        
        with Pool(processes=self.num_workers) as pool:
            while len(self.valid_results) < self.target_valid_sets and self.iteration_count < self.max_iterations:
                # Generate batch of parameters
                batch_params = []
                
                # Generate random parameters
                for _ in range(batch_size):
                    if self.iteration_count >= self.max_iterations:
                        break
                    params = self._generate_random_params()
                    batch_params.append((
                        params,
                        float(self.init_usdt),
                        float(self.init_twd),
                        str(self.csv_path)  # Pass CSV path instead of DataFrame
                    ))
                    self.iteration_count += 1
                
                # Run batch in parallel
                results = pool.map(run_single_backtest, batch_params)
                
                # Process results
                for result in results:
                    if result and result.get('success'):
                        self.valid_results.append(result)
                        stats = result['stats']
                        robustness = stats.get('robustness_score', 0)
                        print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆåƒæ•¸ [{len(self.valid_results)}/{self.target_valid_sets}] | "
                              f"ROI: {stats['roi_pct']:.2f}% | Max DD: {stats['max_drawdown_pct']:.2f}% | "
                              f"Robustness: {robustness:.2f}")
                        
                        # Generate mutations for successful params
                        if len(self.valid_results) < self.target_valid_sets:
                            mutation_params = []
                            for i in range(5):
                                if self.iteration_count >= self.max_iterations:
                                    break
                                mutated = self._mutate_params(result['params'], mutation_rate=0.1)
                                mutation_params.append((
                                    mutated,
                                    float(self.init_usdt),
                                    float(self.init_twd),
                                    str(self.csv_path)
                                ))
                                self.iteration_count += 1
                            
                            # Run mutations in parallel
                            mut_results = pool.map(run_single_backtest, mutation_params)
                            for mut_result in mut_results:
                                if mut_result and mut_result.get('success'):
                                    self.valid_results.append(mut_result)
                                    mut_stats = mut_result['stats']
                                    mut_robustness = mut_stats.get('robustness_score', 0)
                                    print(f"   â””â”€ è®Šç•°æˆåŠŸ | ROI: {mut_stats['roi_pct']:.2f}% | Max DD: {mut_stats['max_drawdown_pct']:.2f}% | Robustness: {mut_robustness:.2f}")
                
                # Progress update with progress bar
                elapsed = time.time() - start_time
                if self.iteration_count % batch_size == 0:
                    rate = self.iteration_count / elapsed if elapsed > 0 else 0
                    remaining = (self.max_iterations - self.iteration_count) / rate if rate > 0 else 0
                    progress_pct = (self.iteration_count / self.max_iterations) * 100
                    bar_length = 50
                    filled = int(bar_length * self.iteration_count / self.max_iterations)
                    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                    print(f"\ré€²åº¦: [{bar}] {progress_pct:.1f}% | "
                          f"è¿­ä»£: {self.iteration_count}/{self.max_iterations} | "
                          f"æœ‰æ•ˆ: {len(self.valid_results)} | "
                          f"é€Ÿåº¦: {rate:.1f} iter/s | "
                          f"å‰©é¤˜: {remaining/60:.1f} min", end='', flush=True)
        
        print()  # New line after progress bar
        total_time = time.time() - start_time
        print("=" * 80)
        print("âœ… å„ªåŒ–å®Œæˆ")
        print(f"   ç¸½è¿­ä»£æ¬¡æ•¸: {self.iteration_count}")
        print(f"   æ‰¾åˆ°æœ‰æ•ˆåƒæ•¸çµ„æ•¸: {len(self.valid_results)}")
        print(f"   ç¸½è€—æ™‚: {total_time/60:.1f} åˆ†é˜ ({total_time/3600:.2f} å°æ™‚)")
        print(f"   å¹³å‡æ¯æ¬¡è¿­ä»£: {total_time/self.iteration_count:.2f} ç§’")
        print("=" * 80)
    
    def save_results(self, output_path: Path):
        """Save all valid results to CSV"""
        if not self.valid_results:
            print("\nâš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆåƒæ•¸ï¼Œç„¡æ³•ä¿å­˜çµæœ")
            print("   å»ºè­°ï¼š")
            print("   1. æ”¾å¯¬ç¯©é¸æ¢ä»¶ï¼ˆé™ä½ROIè¦æ±‚æˆ–æé«˜MaxDDå®¹å¿åº¦ï¼‰")
            print("   2. æ“´å¤§åƒæ•¸æœç´¢ç¯„åœ")
            print("   3. æª¢æŸ¥æ•¸æ“šè³ªé‡")
            return
        
        # ä½¿ç”¨ Robustness Score æ’åºï¼ˆå„ªå…ˆè€ƒæ…®ç©©å¥æ€§ï¼‰
        sorted_results = sorted(
            self.valid_results, 
            key=lambda x: x['stats'].get('robustness_score', 0), 
            reverse=True
        )
        
        csv_data = []
        for result in sorted_results:
            params = result['params']
            stats = result['stats']
            
            row = {
                'robustness_score': stats.get('robustness_score', 0),
                'roi_pct': stats['roi_pct'],
                'max_drawdown_pct': stats['max_drawdown_pct'],
                'sharpe_ratio': stats.get('sharpe_ratio', 0),
                'total_pnl': stats['total_pnl'],
                'total_trades': stats['total_trades'],
                'final_equity': stats['final_equity'],
                'small_gap': params.get('small_gap', ''),
                'mid_mult': params.get('mid_mult', ''),
                'big_mult': params.get('big_mult', ''),
                'size_pct_small': params.get('size_pct_small', ''),
                'size_pct_mid': params.get('size_pct_mid', ''),
                'size_pct_big': params.get('size_pct_big', ''),
                'ema_span_fast_bars': params.get('ema_span_fast_bars', ''),
                'ema_span_slow_bars': params.get('ema_span_slow_bars', ''),
                'bias_high': params.get('bias_high', ''),
                'bias_low': params.get('bias_low', ''),
                'bias_neutral_target': params.get('bias_neutral_target', ''),
                'atr_spacing_multiplier': params.get('atr_spacing_multiplier', ''),
                'trend_trade_equity_pct': params.get('trend_trade_equity_pct', ''),
                'adx_strength_threshold': params.get('adx_strength_threshold', ''),
                'rsi_period': params.get('rsi_period', ''),
                'rsi_bull_threshold': params.get('rsi_bull_threshold', ''),
                'rsi_bear_threshold': params.get('rsi_bear_threshold', ''),
                'adx_min_threshold': params.get('adx_min_threshold', ''),
                'bollinger_window': params.get('bollinger_window', ''),
                'bollinger_k': params.get('bollinger_k', ''),
                'bollinger_band_threshold': params.get('bollinger_band_threshold', ''),
                'stochastic_k_period': params.get('stochastic_k_period', ''),
                'stochastic_d_period': params.get('stochastic_d_period', ''),
                'stochastic_oversold': params.get('stochastic_oversold', ''),
                'stochastic_overbought': params.get('stochastic_overbought', ''),
            }
            csv_data.append(row)
        
        # è™•ç†è¼¸å‡ºè·¯å¾‘ï¼šå¦‚æœæ˜¯ç›®éŒ„ï¼Œåœ¨ç›®éŒ„ä¸­å‰µå»ºæ–‡ä»¶
        if output_path.is_dir():
            output_file = output_path / 'optimization_results.csv'
        else:
            output_file = output_path
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            if csv_data:
                writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
                writer.writeheader()
                writer.writerows(csv_data)
        
        print(f"\nğŸ“Š çµæœå·²ä¿å­˜è‡³: {output_file}")
        print(f"\nğŸ† Top 5 åƒæ•¸çµ„åˆï¼ˆæŒ‰ Robustness Score æ’åºï¼‰:")
        for i, result in enumerate(sorted_results[:5], 1):
            stats = result['stats']
            robustness = stats.get('robustness_score', 0)
            print(f"   {i}. Robustness: {robustness:>6.2f} | ROI: {stats['roi_pct']:>6.2f}% | Max DD: {stats['max_drawdown_pct']:>5.2f}% | "
                  f"Sharpe: {stats.get('sharpe_ratio', 0):>5.2f} | äº¤æ˜“æ¬¡æ•¸: {stats['total_trades']:>4} | ç¸½æç›Š: {stats['total_pnl']:>10.2f} TWD")


def main():
    parser = argparse.ArgumentParser(description="Parallel Parameter Optimization")
    parser.add_argument("--csv", type=Path, default=Path(__file__).parent / "usdttwd_1m_25y7m.csv",
                        help="Path to OHLC CSV file")
    parser.add_argument("--config", type=Path, default=Path(__file__).parent / "config_usdttwd.yaml",
                        help="Path to base config YAML file")
    parser.add_argument("--init-usdt", type=float, default=10000.0, help="Initial USDT balance")
    parser.add_argument("--init-twd", type=float, default=300000.0, help="Initial TWD balance")
    parser.add_argument("--output", type=Path, default=Path(__file__).parent / "optimization_results.csv",
                        help="Output CSV file path")
    parser.add_argument("--target", type=int, default=100, help="Target number of valid parameter sets")
    parser.add_argument("--max-iter", type=int, default=2000, help="Maximum iterations")
    parser.add_argument("--workers", type=int, default=4, help="Number of parallel workers (recommended: 4-6 for M1)")
    
    args = parser.parse_args()
    
    if not args.csv.exists():
        LOG.error(f"CSV file not found: {args.csv}")
        return
    
    if not args.config.exists():
        LOG.error(f"Config file not found: {args.config}")
        return
    
    optimizer = ParameterOptimizerParallel(
        csv_path=args.csv,
        base_config_path=args.config,
        init_usdt=args.init_usdt,
        init_twd=args.init_twd,
        num_workers=args.workers
    )
    
    optimizer.target_valid_sets = args.target
    optimizer.max_iterations = args.max_iter
    
    optimizer.optimize()
    optimizer.save_results(args.output)


if __name__ == "__main__":
    main()

