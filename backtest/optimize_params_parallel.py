# optimize_params_parallel.py
"""
ä¸¦è¡Œç‰ˆæœ¬çš„åƒæ•¸å„ªåŒ–è…³æœ¬ï¼ˆé‡å° Mac M1 å„ªåŒ–ï¼‰
ä½¿ç”¨ multiprocessing å¯¦ç¾çœŸæ­£çš„ä¸¦è¡ŒåŸ·è¡Œ
"""
import argparse
import csv
import logging
import random
from decimal import Decimal
from pathlib import Path
from typing import Dict, List, Optional
from multiprocessing import Pool, Manager
import pandas as pd
import yaml
import time

import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ä»¥å°å…¥ GridStrategy
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# å˜—è©¦å…©ç¨®å°å…¥æ–¹å¼ï¼ˆæ”¯æŒå¾æ ¹ç›®éŒ„æˆ– backtest ç›®éŒ„é‹è¡Œï¼‰
try:
    from backtest.backtest_adapter import BacktestAdapter
except ImportError:
    from backtest_adapter import BacktestAdapter

from strategy_usdttwd_grid_refactored import GridStrategy

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
LOG = logging.getLogger("ParamOptimizerParallel")


def run_single_backtest(args_tuple):
    """å–®å€‹å›æ¸¬ä»»å‹™ï¼ˆç”¨æ–¼å¤šé€²ç¨‹ï¼‰- ä½¿ç”¨ BacktestAdapter ç¢ºä¿é‚è¼¯ä¸€è‡´æ€§"""
    params, init_usdt, init_twd, csv_path = args_tuple
    
    # ä¿å­˜ params ä»¥ä¾¿åœ¨ç•°å¸¸æ™‚ä½¿ç”¨
    saved_params = params.copy() if params else {}

    try:
        # åœ¨æ¯å€‹é€²ç¨‹ä¸­é‡æ–°è¼‰å…¥æ•¸æ“šï¼ˆé¿å…åºåˆ—åŒ–å•é¡Œï¼‰
        temp_df = pd.read_csv(csv_path, usecols=['ts', 'high', 'low', 'close'])

        # Handle timestamp
        if pd.api.types.is_numeric_dtype(temp_df['ts']):
            try:
                tss = pd.to_datetime(temp_df['ts'], unit='ms')
                if tss.min().year < 2000:
                    raise ValueError("ts likely in seconds, not milliseconds.")
            except (ValueError, pd.errors.OutOfBoundsDatetime):
                tss = pd.to_datetime(temp_df['ts'], unit='s')
            temp_df['ts'] = tss
        else:
            temp_df['ts'] = pd.to_datetime(temp_df['ts'])

        price_df = temp_df.set_index('ts')
        price_df['high'] = price_df['high'].astype(float)
        price_df['low'] = price_df['low'].astype(float)
        price_df['close'] = price_df['close'].astype(float)
        price_df.ffill(inplace=True)

        # ä½¿ç”¨ BacktestAdapter å’Œ GridStrategyï¼ˆèˆ‡å¯¦ç›¤ç›¸åŒçš„é‚è¼¯ï¼‰
        strategy = GridStrategy(params)
        adapter = BacktestAdapter(
            strategy=strategy,
            init_usdt=Decimal(str(init_usdt)),
            init_twd=Decimal(str(init_twd)),
            fee_rate=Decimal(str(params.get('taker_fee', '0.0004'))),
            verbose=False
        )

        stats = adapter.run(price_df)
        
        # ç¢ºä¿ stats æœ‰æ‰€æœ‰å¿…è¦çš„æ¬„ä½
        if 'sharpe_ratio' not in stats:
            stats['sharpe_ratio'] = 0.0

        # è¨ˆç®— Robustness Scoreï¼ˆç©©å¥æ€§åˆ†æ•¸ï¼‰
        # Formula: score = roi_pct * 0.4 + (100 / (max_drawdown_pct + 1)) * 0.6
        roi_pct = stats.get('roi_pct', 0.0)
        max_dd_pct = stats.get('max_drawdown_pct', 0.0)
        robustness_score = roi_pct * 0.4 + (100 / (max_dd_pct + 1)) * 0.6

        stats['robustness_score'] = robustness_score
        
        # è¨ºæ–·æ¨¡å¼ï¼šæ°¸é è¿”å›å®Œæ•´çµæœï¼Œä½†æ¨™è¨˜æ˜¯å¦ç‚ºã€Œæœ‰æ•ˆåƒæ•¸ã€
        # æ¨™è¨˜ç‹€æ…‹ï¼šprofit vs loss_or_idle
        status = 'profit' if (stats['roi_pct'] > 0 and stats.get('total_trades', 0) > 0) else 'loss_or_idle'
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºã€Œæœ‰æ•ˆåƒæ•¸ã€ï¼ˆæ»¿è¶³å„ªåŒ–ç›®æ¨™æ¢ä»¶ï¼‰
        # æ¢ä»¶ï¼šROI > 0.5%, MaxDD < 40%, total_trades > 20, Robustness Score > 10
        is_valid = (
            stats['roi_pct'] > 0.5
            and stats['max_drawdown_pct'] < 40.0
            and stats.get('total_trades', 0) > 20
            and robustness_score > 10.0
        )
        
        return {
            'params': params,
            'stats': stats,
            'status': status,
            'is_valid': is_valid,  # æ¨™è¨˜æ˜¯å¦ç‚ºæœ‰æ•ˆåƒæ•¸ï¼ˆç”¨æ–¼å„ªåŒ–ç›®æ¨™ï¼‰
            'success': True  # åªä»£è¡¨ã€Œå›æ¸¬æˆåŠŸå®Œæˆã€ï¼Œä¸ä»£è¡¨ç­–ç•¥å¥½å£
        }
        
    except Exception as e:
        # å³ä½¿ç™¼ç”Ÿç•°å¸¸ï¼Œä¹Ÿè¿”å›ä¸€å€‹çµæœçµæ§‹ï¼ˆç”¨æ–¼è¨ºæ–·ï¼‰
        LOG.warning(f"Backtest failed: {e}")
        import traceback
        traceback.print_exc()
        
        # è¿”å›å¤±æ•—çµæœï¼ŒåŒ…å«éŒ¯èª¤ä¿¡æ¯
        # ä¼°ç®—åˆå§‹æ¬Šç›Šï¼ˆä½¿ç”¨å‚³å…¥çš„åƒæ•¸ï¼‰
        estimated_initial_equity = float(init_usdt) * 30.0 + float(init_twd)
        return {
            'params': saved_params,
            'stats': {
                'roi_pct': 0.0,
                'max_drawdown_pct': 0.0,
                'total_pnl': 0.0,
                'total_trades': 0,
                'robustness_score': 0.0,
                'sharpe_ratio': 0.0,
                'final_equity': estimated_initial_equity,
                'initial_equity': estimated_initial_equity,
            },
            'status': 'error',
            'error_message': str(e),
            'is_valid': False,  # éŒ¯èª¤çµæœä¸ç®—æœ‰æ•ˆåƒæ•¸
            'success': True  # æ¨™è¨˜ç‚ºã€Œå·²è™•ç†ã€ï¼Œä»¥ä¾¿è¢«æ”¶é›†
        }


class ParameterOptimizerParallel:
    """ä¸¦è¡Œç‰ˆæœ¬çš„åƒæ•¸å„ªåŒ–å™¨"""
    
    def __init__(self, csv_path: Path, base_config_path: Path, 
                 init_usdt: float = 10000.0, init_twd: float = 300000.0,
                 num_workers: int = 4):
        self.csv_path = csv_path
        self.base_config_path = base_config_path
        self.init_usdt = Decimal(str(init_usdt))
        self.init_twd = Decimal(str(init_twd))
        self.num_workers = num_workers
        self.base_config = {}
        self.price_df = None
        self.valid_results = []  # åªå­˜å„²æ»¿è¶³æ¢ä»¶çš„ã€Œæœ‰æ•ˆåƒæ•¸ã€
        self.all_results = []    # å­˜å„²æ‰€æœ‰çµæœï¼ˆç”¨æ–¼è¨ºæ–·å’Œ CSV ä¿å­˜ï¼‰
        self.iteration_count = 0
        self.max_iterations = 2000
        self.target_valid_sets = 100
        
        self._load_data()
        self._load_base_config()
    
    def _load_data(self):
        """Load OHLC data from CSV"""
        print(f"ğŸ“‚ è¼‰å…¥æ•¸æ“š: {self.csv_path.name}...")
        try:
            temp_df = pd.read_csv(self.csv_path, usecols=['ts', 'high', 'low', 'close'])
            
            # Handle timestamp
            if pd.api.types.is_numeric_dtype(temp_df['ts']):
                try:
                    tss = pd.to_datetime(temp_df['ts'], unit='ms')
                    if tss.min().year < 2000:
                        raise ValueError("ts likely in seconds, not milliseconds.")
                except (ValueError, pd.errors.OutOfBoundsDatetime):
                    LOG.warning("Could not parse ts as milliseconds, trying seconds...")
                    tss = pd.to_datetime(temp_df['ts'], unit='s')
                temp_df['ts'] = tss
            else:
                temp_df['ts'] = pd.to_datetime(temp_df['ts'])
            
            self.price_df = temp_df.set_index('ts')
            self.price_df['high'] = self.price_df['high'].astype(float)
            self.price_df['low'] = self.price_df['low'].astype(float)
            self.price_df['close'] = self.price_df['close'].astype(float)
            self.price_df.ffill(inplace=True)
            
            print(f"   âœ“ æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(self.price_df):,} æ ¹Kç·š")
        except Exception as e:
            LOG.error(f"Failed to load data: {e}", exc_info=True)
            raise
    
    def _load_base_config(self):
        """Load base configuration"""
        try:
            with open(self.base_config_path, 'r', encoding='utf-8') as f:
                self.base_config = yaml.safe_load(f) or {}
            # Config loaded silently
        except Exception as e:
            LOG.error(f"Failed to load base config: {e}", exc_info=True)
            raise
    
    def _generate_random_params(self) -> Dict:
        """Generate a random set of parameters within defined ranges"""
        params = self.base_config.copy()
        
        # æ–¹å‘1å„ªåŒ–ï¼šé‡é»å„ªåŒ–è¶¨å‹¢è·Ÿéš¨åƒæ•¸ï¼Œç¶²æ ¼ä½œç‚ºè¼”åŠ©
        # ç­–ç•¥èª¿æ•´ï¼šå®Œå…¨è½‰å‘è¶¨å‹¢è·Ÿéš¨ï¼Œç¶²æ ¼ä½œç‚ºè¼”åŠ©
        
        # ATRå‹•æ…‹ç¶²æ ¼ä¹˜æ•¸ï¼ˆæ§åˆ¶å‹•æ…‹é–“è·ï¼Œé€™è£¡ç¯„åœèª¿ä½ï¼Œè®“ç¶²æ ¼æ›´ç·Šå¯†ï¼‰
        if params.get('use_atr_spacing', False):
            params['atr_spacing_multiplier'] = str(round(random.uniform(0.1, 0.8), 3))  # 0.1-0.8 æ›´ç·Šçš„ ATR é–“è·
        
        # ç¶²æ ¼å€æ•¸ï¼ˆå½±éŸ¿ç¶²æ ¼å±¤ç´šé–“è·ï¼‰
        params['mid_mult'] = random.randint(2, 5)  # æ“´å¤§ï¼š2-5
        params['big_mult'] = random.randint(5, 12)  # æ“´å¤§ï¼š5-12
        
        # è¨‚å–®å¤§å°ï¼ˆå½±éŸ¿è³‡é‡‘åˆ©ç”¨ç‡å’Œå–®ç­†åˆ©æ½¤ï¼‰
        # æ‰¾åˆ°çš„æœ‰æ•ˆåƒæ•¸åœ¨0.029-0.068ï¼Œéœ€è¦æé«˜ä»¥å¢åŠ æ”¶ç›Š
        params['size_pct_small'] = str(round(random.uniform(0.03, 0.08), 4))  # æé«˜ï¼š0.03-0.08
        params['size_pct_mid'] = str(round(random.uniform(0.04, 0.10), 4))  # æé«˜ï¼š0.04-0.10
        params['size_pct_big'] = str(round(random.uniform(0.05, 0.12), 4))  # æé«˜ï¼š0.05-0.12
        
        # EMAåƒæ•¸ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–ï¼šèª¿æ•´è‡³æ¥­ç•Œæ¨™æº–ï¼‰
        # æ¥­ç•Œæ¨™æº–ï¼šå¿«ç·š12-50ï¼Œæ…¢ç·š26-200
        params['ema_span_fast_bars'] = random.randint(12, 50)  # æ¥­ç•Œæ¨™æº–ï¼š12-50
        params['ema_span_slow_bars'] = random.randint(26, 200)  # æ¥­ç•Œæ¨™æº–ï¼š26-200
        
        # è¶¨å‹¢åå¥½ï¼ˆå½±éŸ¿å€‰ä½åˆ†é…ï¼‰
        params['bias_high'] = str(round(random.uniform(0.50, 0.80), 3))  # æ“´å¤§ï¼š0.50-0.80
        params['bias_low'] = str(round(random.uniform(0.10, 0.45), 3))  # æ“´å¤§ï¼š0.10-0.45
        params['bias_neutral_target'] = str(round(random.uniform(0.35, 0.60), 3))  # æ“´å¤§ï¼š0.35-0.60
        
        # small_gapï¼šåœ¨æœªå•Ÿç”¨ ATR æˆ–ä½œç‚ºåŸºç¤æ™‚ï¼Œæ§åˆ¶çµ•å°é–“è·ï¼ˆæ”¹ç‚ºéå¸¸ç·Šçš„ç¶²æ ¼ï¼‰
        params['small_gap'] = str(round(random.uniform(0.0005, 0.003), 4))  # 0.0005-0.003 éå¸¸ç·Šçš„ç¶²æ ¼
        
        # Ensure required parameters
        if 'macd_fast_period' not in params:
            params['macd_fast_period'] = 12
        if 'macd_slow_period' not in params:
            params['macd_slow_period'] = 26
        if 'macd_signal_period' not in params:
            params['macd_signal_period'] = 9
        if 'dmi_period' not in params:
            params['dmi_period'] = 14
        if 'grid_aggression_threshold' not in params:
            params['grid_aggression_threshold'] = 20
        if 'grid_aggression_multiplier' not in params:
            params['grid_aggression_multiplier'] = '1.0'
        if 'use_hybrid_model' not in params:
            params['use_hybrid_model'] = True  # å•Ÿç”¨æ··åˆæ¨¡å¼
        if 'use_atr_spacing' not in params:
            params['use_atr_spacing'] = True  # å•Ÿç”¨ATRå‹•æ…‹ç¶²æ ¼
        if 'use_adx_filter' not in params:
            params['use_adx_filter'] = False  # æ–¹å‘1å„ªåŒ–ï¼šç¦ç”¨ADXéæ¿¾å™¨ï¼Œä¸»è¦ä¾é è¶¨å‹¢è·Ÿéš¨
        if 'atr_spacing_multiplier' not in params:
            params['atr_spacing_multiplier'] = str(round(random.uniform(0.3, 1.5), 3))

        # ADX è¶¨å‹¢é€²å ´é–€æª»ï¼šä¿æŒåœ¨ 20-60ï¼Œé¿å…å¤ªæ—©é€²å…¥è¶¨å‹¢æ¨¡å¼ï¼ˆæ¸›å°‘ Zombie è¡Œç‚ºï¼‰
        params['adx_strength_threshold'] = random.randint(20, 60)

        # æ¯å´ç¶²æ ¼å±¤æ•¸ï¼šæ§åˆ¶åœ¨ 5-15ï¼Œé¿å…å±¤æ•¸éå¤šå°è‡´å–®ç­†è¨‚å–®é‡‘é¡éå°
        params['levels_each'] = random.randint(5, 15)
        
        return params
    
    def _mutate_params(self, base_params: Dict, mutation_rate: float = 0.1) -> Dict:
        """Create a mutated variant of parameters"""
        params = base_params.copy()
        
        if 'small_gap' in params:
            val = float(params['small_gap'])
            # åœç¹ 0.0005-0.003 çš„ç¯„åœè¼•å¾®è®Šå‹•ï¼Œä¸¦é™åˆ¶åœ¨æ­¤å€é–“å…§
            mutated = val * (1 + random.uniform(-mutation_rate, mutation_rate))
            mutated = max(0.0005, min(0.003, mutated))
            params['small_gap'] = str(round(mutated, 4))
        
        if 'size_pct_small' in params:
            val = float(params['size_pct_small'])
            params['size_pct_small'] = str(round(max(0.03, min(0.08, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'size_pct_mid' in params:
            val = float(params['size_pct_mid'])
            params['size_pct_mid'] = str(round(max(0.04, min(0.10, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'size_pct_big' in params:
            val = float(params['size_pct_big'])
            params['size_pct_big'] = str(round(max(0.05, min(0.12, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 4))
        
        if 'mid_mult' in params:
            params['mid_mult'] = max(2, min(5, params['mid_mult'] + random.randint(-1, 1)))
        
        if 'big_mult' in params:
            params['big_mult'] = max(5, min(12, params['big_mult'] + random.randint(-1, 1)))
        
        if 'ema_span_fast_bars' in params:
            change = int(params['ema_span_fast_bars'] * mutation_rate)
            params['ema_span_fast_bars'] = max(100, min(600, params['ema_span_fast_bars'] + random.randint(-change, change)))
        
        if 'ema_span_slow_bars' in params:
            change = int(params['ema_span_slow_bars'] * mutation_rate)
            params['ema_span_slow_bars'] = max(300, min(2000, params['ema_span_slow_bars'] + random.randint(-change, change)))
        
        # è¶¨å‹¢è·Ÿéš¨å€‰ä½æ¯”ä¾‹è®Šç•°
        if 'trend_trade_equity_pct' in params:
            val = float(params['trend_trade_equity_pct'])
            params['trend_trade_equity_pct'] = str(round(max(0.6, min(0.85, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        # ADXè¶¨å‹¢é€²å ´é–€æª»è®Šç•°ï¼ˆæ–°ç¯„åœï¼š20-50ï¼Œåœç¹è¼ƒé«˜å€é–“å¾®èª¿ï¼‰
        if 'adx_strength_threshold' in params:
            params['adx_strength_threshold'] = max(
                20,
                min(50, params['adx_strength_threshold'] + random.randint(-2, 2))
            )
        
        # å¤šæŒ‡æ¨™è¤‡åˆåˆ¤æ–·åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–ï¼šèª¿æ•´è‡³æ¥­ç•Œæ¨™æº–ï¼‰
        if 'rsi_period' in params:
            params['rsi_period'] = max(14, min(21, params['rsi_period'] + random.randint(-2, 2)))  # æ¥­ç•Œæ¨™æº–ï¼š14-21
        if 'rsi_bull_threshold' in params:
            val = float(params['rsi_bull_threshold'])
            params['rsi_bull_threshold'] = round(max(50.0, min(60.0, val + random.uniform(-2.0, 2.0))), 1)  # æ¥­ç•Œæ¨™æº–ï¼š50-60
        if 'rsi_bear_threshold' in params:
            val = float(params['rsi_bear_threshold'])
            params['rsi_bear_threshold'] = round(max(40.0, min(50.0, val + random.uniform(-2.0, 2.0))), 1)  # æ¥­ç•Œæ¨™æº–ï¼š40-50
        if 'adx_min_threshold' in params:
            params['adx_min_threshold'] = max(5, min(10, params['adx_min_threshold'] + random.randint(-1, 1)))  # æ¥µåº¦æ”¾å¯¬ï¼š5-10
        # å¸ƒæ—å¸¶åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–æ–°å¢ï¼‰
        if 'bollinger_window' in params:
            params['bollinger_window'] = max(18, min(22, params['bollinger_window'] + random.randint(-1, 1)))
        if 'bollinger_k' in params:
            val = float(params['bollinger_k'])
            params['bollinger_k'] = round(max(1.8, min(2.2, val + random.uniform(-0.1, 0.1))), 1)
        if 'bollinger_band_threshold' in params:
            val = float(params['bollinger_band_threshold'])
            params['bollinger_band_threshold'] = round(max(0.05, min(0.15, val + random.uniform(-0.02, 0.02))), 2)
        # éš¨æ©Ÿéœ‡ç›ªæŒ‡æ¨™åƒæ•¸è®Šç•°ï¼ˆç¬¬å…­æ¬¡å„ªåŒ–æ–°å¢ï¼‰
        if 'stochastic_k_period' in params:
            params['stochastic_k_period'] = max(12, min(16, params['stochastic_k_period'] + random.randint(-1, 1)))
        if 'stochastic_d_period' in params:
            params['stochastic_d_period'] = max(2, min(4, params['stochastic_d_period'] + random.randint(-1, 1)))
        if 'stochastic_oversold' in params:
            val = float(params['stochastic_oversold'])
            params['stochastic_oversold'] = round(max(25.0, min(35.0, val + random.uniform(-2.0, 2.0))), 1)
        if 'stochastic_overbought' in params:
            val = float(params['stochastic_overbought'])
            params['stochastic_overbought'] = round(max(65.0, min(75.0, val + random.uniform(-2.0, 2.0))), 1)
        
        # ATRå‹•æ…‹ç¶²æ ¼ä¹˜æ•¸è®Šç•°ï¼ˆä¿æŒåœ¨ 0.1-0.8 ç¯„åœå…§ï¼‰
        if 'atr_spacing_multiplier' in params:
            val = float(params['atr_spacing_multiplier'])
            mutated = val * (1 + random.uniform(-mutation_rate, mutation_rate))
            mutated = max(0.1, min(0.8, mutated))
            params['atr_spacing_multiplier'] = str(round(mutated, 3))
        
        # ç¶²æ ¼å±¤ç´šæ•¸é‡è®Šç•°ï¼šä¿æŒåœ¨ 5-15 ç¯„åœå…§
        if 'levels_each' in params:
            params['levels_each'] = max(5, min(15, params['levels_each'] + random.randint(-2, 2)))
        
        if 'bias_high' in params:
            val = float(params['bias_high'])
            params['bias_high'] = str(round(max(0.50, min(0.80, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        if 'bias_low' in params:
            val = float(params['bias_low'])
            params['bias_low'] = str(round(max(0.10, min(0.45, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        if 'bias_neutral_target' in params:
            val = float(params['bias_neutral_target'])
            params['bias_neutral_target'] = str(round(max(0.35, min(0.60, val * (1 + random.uniform(-mutation_rate, mutation_rate)))), 3))
        
        return params
    
    def optimize(self):
        """Run parallel optimization"""
        print("=" * 80)
        print("ğŸš€ åƒæ•¸å„ªåŒ–é–‹å§‹")
        print(f"   å·¥ä½œé€²ç¨‹æ•¸: {self.num_workers}")
        print(f"   ç›®æ¨™æœ‰æ•ˆåƒæ•¸çµ„æ•¸: {self.target_valid_sets}")
        print(f"   æœ€å¤§è¿­ä»£æ¬¡æ•¸: {self.max_iterations}")
        print(f"   ç¯©é¸æ¢ä»¶: ROI > 0.5% AND Max Drawdown < 15% AND Robustness Score > 10")
        print("=" * 80)
        
        start_time = time.time()
        batch_size = self.num_workers * 2  # Process in batches
        
        with Pool(processes=self.num_workers) as pool:
            while (len(self.valid_results) < self.target_valid_sets and 
                   self.iteration_count < self.max_iterations):
                # Generate batch of parameters
                batch_params = []
                
                # Generate random parameters
                for _ in range(batch_size):
                    if self.iteration_count >= self.max_iterations:
                        break
                    params = self._generate_random_params()
                    batch_params.append((
                        params,
                        float(self.init_usdt),
                        float(self.init_twd),
                        str(self.csv_path)  # Pass CSV path instead of DataFrame
                    ))
                    self.iteration_count += 1
                
                # Run batch in parallel
                results = pool.map(run_single_backtest, batch_params)
                
                # è¨ºæ–·ï¼šæª¢æŸ¥çµæœæ•¸é‡
                if len(results) != len(batch_params):
                    LOG.warning(f"Result count mismatch: expected {len(batch_params)}, got {len(results)}")
                
                # Process results (è¨ºæ–·æ¨¡å¼ï¼šæ”¶é›†æ‰€æœ‰çµæœï¼Œä½†å€åˆ†æœ‰æ•ˆåƒæ•¸)
                for idx, result in enumerate(results):
                    # æ›´å¯¬é¬†çš„æª¢æŸ¥ï¼šåªè¦æœ‰ result å°±å˜—è©¦è™•ç†
                    if not result:
                        LOG.warning(f"Empty result at batch index {idx}, creating default result")
                        # å³ä½¿çµæœç‚ºç©ºï¼Œä¹Ÿå‰µå»ºä¸€å€‹é»˜èªçµæœä»¥ä¾¿è¨ºæ–·
                        result = {
                            'params': batch_params[idx][0] if idx < len(batch_params) else {},
                            'stats': {
                                'roi_pct': 0.0,
                                'max_drawdown_pct': 0.0,
                                'total_pnl': 0.0,
                                'total_trades': 0,
                                'robustness_score': 0.0,
                                'sharpe_ratio': 0.0,
                                'final_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                                'initial_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                            },
                            'status': 'error',
                            'error_message': 'Empty result from pool.map()',
                            'is_valid': False,
                            'success': False
                        }
                    
                    # ç¢ºä¿çµæœæœ‰å¿…è¦çš„æ¬„ä½ï¼Œå¦‚æœæ²’æœ‰å‰‡è£œå…¨
                    if 'stats' not in result:
                        LOG.warning(f"Result missing 'stats', creating default: {result}")
                        result['stats'] = {
                            'roi_pct': 0.0,
                            'max_drawdown_pct': 0.0,
                            'total_pnl': 0.0,
                            'total_trades': 0,
                            'robustness_score': 0.0,
                            'sharpe_ratio': 0.0,
                            'final_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                            'initial_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                        }
                    
                    if 'params' not in result:
                        LOG.warning(f"Result missing 'params', using empty dict")
                        result['params'] = {}
                    
                    if 'status' not in result:
                        result['status'] = 'unknown'
                    
                    if 'is_valid' not in result:
                        result['is_valid'] = False

                    # æ‰€æœ‰çµæœéƒ½æ·»åŠ åˆ° all_resultsï¼ˆç”¨æ–¼è¨ºæ–·å’Œ CSV ä¿å­˜ï¼‰
                    try:
                        self.all_results.append(result)
                    except Exception as e:
                        LOG.error(f"Failed to append result: {e}, result type: {type(result)}")
                        # å³ä½¿è¿½åŠ å¤±æ•—ï¼Œä¹Ÿå˜—è©¦å‰µå»ºä¸€å€‹æœ€å°çµæœ
                        self.all_results.append({
                            'params': {},
                            'stats': {
                                'roi_pct': 0.0,
                                'max_drawdown_pct': 0.0,
                                'total_pnl': 0.0,
                                'total_trades': 0,
                                'robustness_score': 0.0,
                                'sharpe_ratio': 0.0,
                                'final_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                                'initial_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                            },
                            'status': 'error',
                            'error_message': f'Failed to process result: {str(e)}',
                            'is_valid': False,
                            'success': False
                        })
                    
                    # åªæœ‰æ»¿è¶³æ¢ä»¶çš„æ‰æ·»åŠ åˆ° valid_resultsï¼ˆç”¨æ–¼å„ªåŒ–ç›®æ¨™çµ±è¨ˆï¼‰
                    if result.get('is_valid', False):
                        self.valid_results.append(result)
                    
                    stats = result['stats']
                    params = result['params']
                    status = result.get('status', 'unknown')

                    robustness = stats.get('robustness_score', 0)
                    trades = stats.get('total_trades', 0)
                    total_pnl = stats.get('total_pnl', 0.0)
                    adx_thr = params.get('adx_strength_threshold', 'NA')
                    small_gap = float(params.get('small_gap', 0.0))

                    # æ¯ 10 æ¬¡è¿­ä»£è¼¸å‡ºä¸€æ¬¡è¨ºæ–·è³‡è¨Š
                    if len(self.all_results) % 10 == 0:
                        error_msg = result.get('error_message', '')
                        error_suffix = f" | ERROR: {error_msg}" if error_msg else ""
                        is_valid_marker = "âœ…" if result.get('is_valid', False) else "âŒ"
                        print(
                            f"[Iter {len(self.all_results)}] {is_valid_marker} Status: {status} | "
                            f"Trades: {trades} | ROI: {stats['roi_pct']:.2f}% | "
                            f"MaxDD: {stats['max_drawdown_pct']:.2f}% | "
                            f"Gap: {small_gap:.4f} | ADX_Th: {adx_thr} | "
                            f"Total PnL: {total_pnl:.2f} | Robustness: {robustness:.2f}{error_suffix}"
                        )
                        
                        # Generate mutations for successful paramsï¼ˆåƒ…å°æœ‰äº¤æ˜“çš„çµæœé€²è¡Œè®Šç•°ï¼‰
                        if len(self.valid_results) < self.target_valid_sets and trades > 0:
                            mutation_params = []
                            for i in range(5):
                                if self.iteration_count >= self.max_iterations:
                                    break
                                mutated = self._mutate_params(params, mutation_rate=0.1)
                                mutation_params.append(
                                    (
                                        mutated,
                                        float(self.init_usdt),
                                        float(self.init_twd),
                                        str(self.csv_path),
                                    )
                                )
                                self.iteration_count += 1

                            # Run mutations in parallel
                            mut_results = pool.map(run_single_backtest, mutation_params)
                            for mut_idx, mut_result in enumerate(mut_results):
                                # æ›´å¯¬é¬†çš„æª¢æŸ¥
                                if not mut_result:
                                    LOG.warning(f"Empty mutation result at index {mut_idx}")
                                    continue
                                
                                # ç¢ºä¿çµæœæœ‰å¿…è¦çš„æ¬„ä½
                                if 'stats' not in mut_result:
                                    mut_result['stats'] = {
                                        'roi_pct': 0.0,
                                        'max_drawdown_pct': 0.0,
                                        'total_pnl': 0.0,
                                        'total_trades': 0,
                                        'robustness_score': 0.0,
                                        'sharpe_ratio': 0.0,
                                        'final_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                                        'initial_equity': float(self.init_usdt) * 30.0 + float(self.init_twd),
                                    }
                                if 'params' not in mut_result:
                                    mut_result['params'] = {}
                                if 'status' not in mut_result:
                                    mut_result['status'] = 'unknown'
                                if 'is_valid' not in mut_result:
                                    mut_result['is_valid'] = False
                                
                                # æ‰€æœ‰çµæœéƒ½æ·»åŠ åˆ° all_results
                                self.all_results.append(mut_result)
                                # åªæœ‰æ»¿è¶³æ¢ä»¶çš„æ‰æ·»åŠ åˆ° valid_results
                                if mut_result.get('is_valid', False):
                                    self.valid_results.append(mut_result)
                                mut_stats = mut_result['stats']
                                mut_params = mut_result['params']
                                mut_robustness = mut_stats.get('robustness_score', 0)
                                mut_trades = mut_stats.get('total_trades', 0)
                                mut_total_pnl = mut_stats.get('total_pnl', 0.0)
                                mut_adx_thr = mut_params.get('adx_strength_threshold', 'NA')
                                mut_small_gap = float(mut_params.get('small_gap', 0.0))
                                mut_status = mut_result.get('status', 'unknown')
                                mut_error_msg = mut_result.get('error_message', '')
                                mut_error_suffix = f" | ERROR: {mut_error_msg}" if mut_error_msg else ""
                                print(
                                    f"   â””â”€ è®Šç•° [{mut_status}] | Trades: {mut_trades} | ROI: {mut_stats['roi_pct']:.2f}% | "
                                    f"MaxDD: {mut_stats['max_drawdown_pct']:.2f}% | "
                                    f"Gap: {mut_small_gap:.4f} | ADX_Th: {mut_adx_thr} | "
                                    f"Total PnL: {mut_total_pnl:.2f} | Robustness: {mut_robustness:.2f}{mut_error_suffix}"
                                )
                
                # Progress update with progress bar
                elapsed = time.time() - start_time
                if self.iteration_count % batch_size == 0:
                    rate = self.iteration_count / elapsed if elapsed > 0 else 0
                    remaining = (self.max_iterations - self.iteration_count) / rate if rate > 0 else 0
                    progress_pct = (self.iteration_count / self.max_iterations) * 100
                    bar_length = 50
                    filled = int(bar_length * self.iteration_count / self.max_iterations)
                    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
                    print(f"\ré€²åº¦: [{bar}] {progress_pct:.1f}% | "
                          f"è¿­ä»£: {self.iteration_count}/{self.max_iterations} | "
                          f"æœ‰æ•ˆ: {len(self.valid_results)}/{len(self.all_results)} | "
                          f"é€Ÿåº¦: {rate:.1f} iter/s | "
                          f"å‰©é¤˜: {remaining/60:.1f} min", end='', flush=True)
        
        print()  # New line after progress bar
        total_time = time.time() - start_time
        print("=" * 80)
        print("âœ… å„ªåŒ–å®Œæˆ")
        print(f"   ç¸½è¿­ä»£æ¬¡æ•¸: {self.iteration_count}")
        print(f"   æ”¶é›†åˆ°çµæœç¸½æ•¸: {len(self.all_results)}")
        print(f"   æ‰¾åˆ°æœ‰æ•ˆåƒæ•¸çµ„æ•¸: {len(self.valid_results)}")
        print(f"   ç¸½è€—æ™‚: {total_time/60:.1f} åˆ†é˜ ({total_time/3600:.2f} å°æ™‚)")
        if self.iteration_count > 0:
            print(f"   å¹³å‡æ¯æ¬¡è¿­ä»£: {total_time/self.iteration_count:.2f} ç§’")
        print("=" * 80)
    
    def save_results(self, output_path: Path):
        """Save all results to CSV (è¨ºæ–·æ¨¡å¼ï¼šåŒ…å«æ‰€æœ‰çµæœï¼ŒåŒ…æ‹¬å¤±æ•—çš„)"""
        if not self.all_results:
            print("\nâš ï¸  æœªæ”¶é›†åˆ°ä»»ä½•çµæœï¼ˆåŒ…æ‹¬å¤±æ•—çš„ï¼‰")
            print(f"   è¨ºæ–·ä¿¡æ¯ï¼š")
            print(f"   - ç¸½è¿­ä»£æ¬¡æ•¸: {self.iteration_count}")
            print(f"   - all_results é•·åº¦: {len(self.all_results)}")
            print(f"   - valid_results é•·åº¦: {len(self.valid_results)}")
            print("   å¯èƒ½åŸå› ï¼š")
            print("   1. æ‰€æœ‰å›æ¸¬éƒ½ç™¼ç”Ÿç•°å¸¸ä¸”æœªè¢«æ•ç²")
            print("   2. æ•¸æ“šæ–‡ä»¶ç„¡æ³•è®€å–")
            print("   3. é…ç½®åƒæ•¸éŒ¯èª¤")
            print("   4. å¤šé€²ç¨‹é€šä¿¡å•é¡Œ")
            # å³ä½¿æ²’æœ‰çµæœï¼Œä¹Ÿå‰µå»ºä¸€å€‹ç©ºçš„ CSV æ–‡ä»¶ä»¥ä¾¿è¨ºæ–·
            output_file = output_path if not output_path.is_dir() else output_path / 'optimization_results.csv'
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=['error', 'iteration_count', 'message'])
                writer.writeheader()
                writer.writerow({
                    'error': 'NO_RESULTS_COLLECTED',
                    'iteration_count': self.iteration_count,
                    'message': 'No results were collected during optimization'
                })
            print(f"\nğŸ“Š å·²å‰µå»ºç©ºçš„è¨ºæ–· CSV: {output_file}")
            return
        
        print(f"\nğŸ“Š æº–å‚™ä¿å­˜ {len(self.all_results)} å€‹çµæœï¼ˆåŒ…å«æ‰€æœ‰æˆåŠŸå’Œå¤±æ•—çš„ï¼‰...")
        print(f"   å…¶ä¸­æœ‰æ•ˆåƒæ•¸: {len(self.valid_results)} å€‹")
        
        # ä½¿ç”¨ total_pnl æ’åºï¼ˆå„ªå…ˆè€ƒæ…®ã€Œè³ºæœ€å¤šéŒ¢ã€çš„ç­–ç•¥ï¼‰
        sorted_results = sorted(
            self.all_results,
            key=lambda x: x['stats']['total_pnl'],
            reverse=True
        )
        
        csv_data = []
        for result in sorted_results:
            params = result['params']
            stats = result['stats']
            
            row = {
                'is_valid': result.get('is_valid', False),
                'status': result.get('status', 'unknown'),
                'error_message': result.get('error_message', ''),
                'robustness_score': stats.get('robustness_score', 0),
                'roi_pct': stats['roi_pct'],
                'max_drawdown_pct': stats['max_drawdown_pct'],
                'sharpe_ratio': stats.get('sharpe_ratio', 0),
                'total_pnl': stats['total_pnl'],
                'total_trades': stats['total_trades'],
                'final_equity': stats.get('final_equity', 0),
                'small_gap': params.get('small_gap', ''),
                'mid_mult': params.get('mid_mult', ''),
                'big_mult': params.get('big_mult', ''),
                'size_pct_small': params.get('size_pct_small', ''),
                'size_pct_mid': params.get('size_pct_mid', ''),
                'size_pct_big': params.get('size_pct_big', ''),
                'ema_span_fast_bars': params.get('ema_span_fast_bars', ''),
                'ema_span_slow_bars': params.get('ema_span_slow_bars', ''),
                'bias_high': params.get('bias_high', ''),
                'bias_low': params.get('bias_low', ''),
                'bias_neutral_target': params.get('bias_neutral_target', ''),
                'atr_spacing_multiplier': params.get('atr_spacing_multiplier', ''),
                'trend_trade_equity_pct': params.get('trend_trade_equity_pct', ''),
                'adx_strength_threshold': params.get('adx_strength_threshold', ''),
                'rsi_period': params.get('rsi_period', ''),
                'rsi_bull_threshold': params.get('rsi_bull_threshold', ''),
                'rsi_bear_threshold': params.get('rsi_bear_threshold', ''),
                'adx_min_threshold': params.get('adx_min_threshold', ''),
                'bollinger_window': params.get('bollinger_window', ''),
                'bollinger_k': params.get('bollinger_k', ''),
                'bollinger_band_threshold': params.get('bollinger_band_threshold', ''),
                'stochastic_k_period': params.get('stochastic_k_period', ''),
                'stochastic_d_period': params.get('stochastic_d_period', ''),
                'stochastic_oversold': params.get('stochastic_oversold', ''),
                'stochastic_overbought': params.get('stochastic_overbought', ''),
            }
            csv_data.append(row)
        
        # è™•ç†è¼¸å‡ºè·¯å¾‘ï¼šå¦‚æœæ˜¯ç›®éŒ„ï¼Œåœ¨ç›®éŒ„ä¸­å‰µå»ºæ–‡ä»¶
        if output_path.is_dir():
            output_file = output_path / 'optimization_results.csv'
        else:
            output_file = output_path
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            if csv_data:
                writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
                writer.writeheader()
                writer.writerows(csv_data)
        
        print(f"\nğŸ“Š çµæœå·²ä¿å­˜è‡³: {output_file}")
        
        # çµ±è¨ˆçµæœåˆ†å¸ƒ
        status_counts = {}
        for r in sorted_results:
            status = r.get('status', 'unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        print(f"\nğŸ“ˆ çµæœçµ±è¨ˆ:")
        for status, count in status_counts.items():
            print(f"   {status}: {count} å€‹")
        
        # é¡¯ç¤º Top 5 æœ‰æ•ˆåƒæ•¸ï¼ˆæŒ‰ Total PnLï¼‰
        valid_sorted = sorted(
            self.valid_results,
            key=lambda x: x['stats']['total_pnl'],
            reverse=True
        )
        if valid_sorted:
            print(f"\nğŸ† Top 5 æœ‰æ•ˆåƒæ•¸çµ„åˆï¼ˆæŒ‰ Total PnL æ’åºï¼‰:")
            for i, result in enumerate(valid_sorted[:5], 1):
                stats = result['stats']
                robustness = stats.get('robustness_score', 0)
                print(f"   {i}. Total PnL: {stats['total_pnl']:>10.2f} TWD | "
                      f"ROI: {stats['roi_pct']:>6.2f}% | Max DD: {stats['max_drawdown_pct']:>5.2f}% | "
                      f"Sharpe: {stats.get('sharpe_ratio', 0):>5.2f} | "
                      f"Trades: {stats['total_trades']:>4} | Robustness: {robustness:>6.2f}")
        else:
            print(f"\nâš ï¸  æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆåƒæ•¸ï¼ˆæ»¿è¶³ ROI > 0.5%, MaxDD < 40%, Trades > 20, Robustness > 10ï¼‰")
        
        # é¡¯ç¤º Top 5 ç›ˆåˆ©çµæœï¼ˆåŒ…æ‹¬æœªé”æ¨™çš„ï¼‰
        profitable_results = [r for r in sorted_results if r['stats']['total_pnl'] > 0 and not r.get('is_valid', False)]
        if profitable_results:
            print(f"\nğŸ“ˆ Top 5 ç›ˆåˆ©ä½†æœªé”æ¨™çš„çµæœï¼ˆæŒ‰ Total PnL æ’åºï¼‰:")
            for i, result in enumerate(profitable_results[:5], 1):
                stats = result['stats']
                robustness = stats.get('robustness_score', 0)
                print(f"   {i}. Total PnL: {stats['total_pnl']:>10.2f} TWD | "
                      f"ROI: {stats['roi_pct']:>6.2f}% | Max DD: {stats['max_drawdown_pct']:>5.2f}% | "
                      f"Trades: {stats['total_trades']:>4} | Robustness: {robustness:>6.2f}")
        
        # é¡¯ç¤ºå¤±æ•—æ¡ˆä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
        error_results = [r for r in sorted_results if r.get('status') == 'error']
        if error_results:
            print(f"\nâŒ å¤±æ•—æ¡ˆä¾‹ï¼ˆå‰ 5 å€‹ï¼‰:")
            for i, result in enumerate(error_results[:5], 1):
                error_msg = result.get('error_message', 'Unknown error')
                print(f"   {i}. Error: {error_msg[:100]}...")
        
        # é¡¯ç¤ºç„¡äº¤æ˜“æ¡ˆä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
        no_trade_results = [r for r in sorted_results if r['stats']['total_trades'] == 0 and r.get('status') != 'error']
        if no_trade_results:
            print(f"\nğŸ’¤ ç„¡äº¤æ˜“æ¡ˆä¾‹ï¼ˆå‰ 5 å€‹ï¼‰:")
            for i, result in enumerate(no_trade_results[:5], 1):
                params = result['params']
                stats = result['stats']
                print(f"   {i}. Gap: {params.get('small_gap', 'N/A')} | "
                      f"ADX_Th: {params.get('adx_strength_threshold', 'N/A')} | "
                      f"ROI: {stats['roi_pct']:.2f}% | MaxDD: {stats['max_drawdown_pct']:.2f}%")


def main():
    parser = argparse.ArgumentParser(description="Parallel Parameter Optimization")
    parser.add_argument("--csv", type=Path, default=Path(__file__).parent / "usdttwd_1m_25y7m.csv",
                        help="Path to OHLC CSV file")
    parser.add_argument("--config", type=Path, default=Path(__file__).parent / "config_usdttwd.yaml",
                        help="Path to base config YAML file")
    parser.add_argument("--init-usdt", type=float, default=10000.0, help="Initial USDT balance")
    parser.add_argument("--init-twd", type=float, default=300000.0, help="Initial TWD balance")
    parser.add_argument("--output", type=Path, default=Path(__file__).parent / "optimization_results.csv",
                        help="Output CSV file path")
    parser.add_argument("--target", type=int, default=100, help="Target number of valid parameter sets")
    parser.add_argument("--max-iter", type=int, default=2000, help="Maximum iterations")
    parser.add_argument("--workers", type=int, default=4, help="Number of parallel workers (recommended: 4-6 for M1)")
    
    args = parser.parse_args()
    
    if not args.csv.exists():
        LOG.error(f"CSV file not found: {args.csv}")
        return
    
    if not args.config.exists():
        LOG.error(f"Config file not found: {args.config}")
        return
    
    optimizer = ParameterOptimizerParallel(
        csv_path=args.csv,
        base_config_path=args.config,
        init_usdt=args.init_usdt,
        init_twd=args.init_twd,
        num_workers=args.workers
    )
    
    optimizer.target_valid_sets = args.target
    optimizer.max_iterations = args.max_iter
    
    optimizer.optimize()
    optimizer.save_results(args.output)


if __name__ == "__main__":
    main()

