#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç­–ç•¥è¨ºæ–·åˆ†æå·¥å…·
é‹è¡Œæ¨£æœ¬å›æ¸¬ï¼Œæ”¶é›†è¨ºæ–·æ•¸æ“šï¼Œè­˜åˆ¥ç­–ç•¥å•é¡Œ
"""

import argparse
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from decimal import Decimal
from typing import Dict, List
import yaml
import random
from datetime import datetime

import sys
from pathlib import Path

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘ä»¥ä¾¿å°å…¥
sys.path.insert(0, str(Path(__file__).parent))

from backtester_grid import Backtester

LOG = logging.getLogger("StrategyDiagnostic")
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - [%(name)s] %(message)s",
    level=logging.INFO
)


class StrategyDiagnostic:
    """ç­–ç•¥è¨ºæ–·åˆ†æå™¨"""
    
    def __init__(self, csv_path: Path, base_config_path: Path, init_usdt: float, init_twd: float):
        self.csv_path = csv_path
        self.base_config_path = base_config_path
        self.init_usdt = Decimal(str(init_usdt))
        self.init_twd = Decimal(str(init_twd))
        self.price_df = None
        self.base_config = None
        self.results = []
        
        self._load_data()
        self._load_base_config()
    
    def _load_data(self):
        """è¼‰å…¥OHLCæ•¸æ“š"""
        LOG.info(f"è¼‰å…¥æ•¸æ“š: {self.csv_path.name}...")
        try:
            temp_df = pd.read_csv(self.csv_path, usecols=['ts', 'high', 'low', 'close'])
            
            # è™•ç†æ™‚é–“æˆ³
            if pd.api.types.is_numeric_dtype(temp_df['ts']):
                try:
                    tss = pd.to_datetime(temp_df['ts'], unit='ms')
                    if tss.min().year < 2000:
                        raise ValueError("ts likely in seconds, not milliseconds.")
                except (ValueError, pd.errors.OutOfBoundsDatetime):
                    LOG.warning("ç„¡æ³•è§£ææ¯«ç§’æ™‚é–“æˆ³ï¼Œå˜—è©¦ç§’...")
                    tss = pd.to_datetime(temp_df['ts'], unit='s')
                temp_df['ts'] = tss
            else:
                temp_df['ts'] = pd.to_datetime(temp_df['ts'])
            
            self.price_df = temp_df.set_index('ts')
            self.price_df['high'] = self.price_df['high'].astype(float)
            self.price_df['low'] = self.price_df['low'].astype(float)
            self.price_df['close'] = self.price_df['close'].astype(float)
            self.price_df.ffill(inplace=True)
            
            LOG.info(f"âœ“ æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(self.price_df):,} æ ¹Kç·š")
            LOG.info(f"  æ™‚é–“ç¯„åœ: {self.price_df.index[0]} è‡³ {self.price_df.index[-1]}")
        except Exception as e:
            LOG.error(f"è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}", exc_info=True)
            raise
    
    def _load_base_config(self):
        """è¼‰å…¥åŸºç¤é…ç½®"""
        try:
            with open(self.base_config_path, 'r', encoding='utf-8') as f:
                self.base_config = yaml.safe_load(f) or {}
        except Exception as e:
            LOG.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}", exc_info=True)
            raise
    
    def _generate_sample_params(self, n: int = 20) -> List[Dict]:
        """ç”Ÿæˆæ¨£æœ¬åƒæ•¸çµ„åˆ"""
        samples = []
        for i in range(n):
            params = self.base_config.copy()
            
            # éš¨æ©Ÿç”Ÿæˆåƒæ•¸ï¼ˆä½¿ç”¨èˆ‡å„ªåŒ–å™¨ç›¸åŒçš„ç¯„åœï¼‰
            params['small_gap'] = str(round(random.uniform(0.01, 0.10), 4))
            params['mid_mult'] = random.randint(2, 6)
            params['big_mult'] = random.randint(5, 15)
            params['size_pct_small'] = str(round(random.uniform(0.01, 0.05), 4))
            params['size_pct_mid'] = str(round(random.uniform(0.015, 0.06), 4))
            params['size_pct_big'] = str(round(random.uniform(0.02, 0.08), 4))
            params['ema_span_fast_bars'] = random.randint(30, 1200)
            params['ema_span_slow_bars'] = random.randint(600, 8000)
            params['bias_high'] = str(round(random.uniform(0.50, 0.90), 3))
            params['bias_low'] = str(round(random.uniform(0.05, 0.50), 3))
            params['bias_neutral_target'] = str(round(random.uniform(0.30, 0.60), 3))
            
            # ç¢ºä¿å¿…è¦åƒæ•¸å­˜åœ¨
            if 'macd_fast_period' not in params:
                params['macd_fast_period'] = 12
            if 'macd_slow_period' not in params:
                params['macd_slow_period'] = 26
            if 'macd_signal_period' not in params:
                params['macd_signal_period'] = 9
            if 'dmi_period' not in params:
                params['dmi_period'] = 14
            if 'grid_aggression_threshold' not in params:
                params['grid_aggression_threshold'] = 20
            if 'grid_aggression_multiplier' not in params:
                params['grid_aggression_multiplier'] = '1.0'
            if 'use_hybrid_model' not in params:
                params['use_hybrid_model'] = True
            
            samples.append(params)
        
        return samples
    
    def run_diagnosis(self, n_samples: int = 20) -> pd.DataFrame:
        """é‹è¡Œè¨ºæ–·åˆ†æ"""
        LOG.info("=" * 80)
        LOG.info("é–‹å§‹ç­–ç•¥è¨ºæ–·åˆ†æ")
        LOG.info(f"æ¨£æœ¬æ•¸é‡: {n_samples}")
        LOG.info("=" * 80)
        
        sample_params = self._generate_sample_params(n_samples)
        
        for i, params in enumerate(sample_params, 1):
            LOG.info(f"\n[{i}/{n_samples}] é‹è¡Œæ¨£æœ¬å›æ¸¬...")
            try:
                backtester = Backtester(params, self.init_usdt, self.init_twd, verbose=False)
                stats = backtester.run(self.price_df, collect_diagnostics=True)
                
                # æ·»åŠ åƒæ•¸ä¿¡æ¯
                result = {
                    'sample_id': i,
                    'small_gap': float(params['small_gap']),
                    'mid_mult': params['mid_mult'],
                    'big_mult': params['big_mult'],
                    'size_pct_small': float(params['size_pct_small']),
                    'ema_span_fast': params['ema_span_fast_bars'],
                    'ema_span_slow': params['ema_span_slow_bars'],
                    **stats  # åŒ…å«æ‰€æœ‰å›æ¸¬çµ±è¨ˆå’Œè¨ºæ–·æ•¸æ“š
                }
                
                self.results.append(result)
                
                LOG.info(f"  ROI: {stats['roi_pct']:.2f}% | "
                        f"Max DD: {stats['max_drawdown_pct']:.2f}% | "
                        f"äº¤æ˜“æ¬¡æ•¸: {stats['total_trades']} | "
                        f"æ‰‹çºŒè²»: {stats.get('total_fee_cost', 0):.2f} TWD")
                
            except Exception as e:
                LOG.error(f"  æ¨£æœ¬ {i} å›æ¸¬å¤±æ•—: {e}")
                continue
        
        # è½‰æ›ç‚ºDataFrame
        if not self.results:
            LOG.warning("æ²’æœ‰æˆåŠŸå®Œæˆçš„å›æ¸¬æ¨£æœ¬")
            return pd.DataFrame()
        
        df = pd.DataFrame(self.results)
        return df
    
    def analyze_results(self, results_df: pd.DataFrame) -> Dict:
        """åˆ†æè¨ºæ–·çµæœ"""
        if results_df.empty:
            return {}
        
        analysis = {}
        
        # åŸºæœ¬çµ±è¨ˆ
        analysis['avg_roi'] = results_df['roi_pct'].mean()
        analysis['median_roi'] = results_df['roi_pct'].median()
        analysis['min_roi'] = results_df['roi_pct'].min()
        analysis['max_roi'] = results_df['roi_pct'].max()
        analysis['positive_roi_count'] = (results_df['roi_pct'] > 0).sum()
        analysis['positive_roi_pct'] = (results_df['roi_pct'] > 0).sum() / len(results_df) * 100
        
        analysis['avg_max_dd'] = results_df['max_drawdown_pct'].mean()
        analysis['max_dd_max'] = results_df['max_drawdown_pct'].max()
        
        # æ‰‹çºŒè²»åˆ†æ
        if 'total_fee_cost' in results_df.columns:
            analysis['avg_fee_cost'] = results_df['total_fee_cost'].mean()
            analysis['total_fee_cost_max'] = results_df['total_fee_cost'].max()
            analysis['avg_fee_to_profit_ratio'] = results_df['fee_to_profit_ratio'].replace([np.inf, -np.inf], np.nan).mean()
        
        # äº¤æ˜“é »ç‡åˆ†æ
        if 'total_trades' in results_df.columns:
            analysis['avg_trades'] = results_df['total_trades'].mean()
            analysis['avg_profit_per_trade'] = results_df.get('avg_profit_per_trade', pd.Series([0])).mean()
        
        # ç¶²æ ¼æˆäº¤ç‡åˆ†æ
        if 'grid_fill_rate' in results_df.columns:
            analysis['avg_grid_fill_rate'] = results_df['grid_fill_rate'].mean()
            analysis['avg_grid_fills'] = results_df['grid_fills'].mean()
        
        # è¶¨å‹¢æ¨¡å¼åˆ†æ
        if 'trend_entries' in results_df.columns:
            analysis['avg_trend_entries'] = results_df['trend_entries'].mean()
            analysis['avg_trend_exits'] = results_df['trend_exits'].mean()
        
        # åƒ¹æ ¼æ³¢å‹•åˆ†æ
        if 'price_range_pct' in results_df.columns:
            analysis['avg_price_range_pct'] = results_df['price_range_pct'].mean()
        
        return analysis
    
    def generate_report(self, results_df: pd.DataFrame, analysis: Dict, output_path: Path):
        """ç”Ÿæˆè¨ºæ–·å ±å‘Š"""
        LOG.info("\n" + "=" * 80)
        LOG.info("è¨ºæ–·å ±å‘Š")
        LOG.info("=" * 80)
        
        # åŸºæœ¬çµ±è¨ˆ
        LOG.info(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        LOG.info(f"  å¹³å‡ ROI: {analysis.get('avg_roi', 0):.2f}%")
        LOG.info(f"  ä¸­ä½æ•¸ ROI: {analysis.get('median_roi', 0):.2f}%")
        LOG.info(f"  ROI ç¯„åœ: {analysis.get('min_roi', 0):.2f}% ~ {analysis.get('max_roi', 0):.2f}%")
        LOG.info(f"  ç›ˆåˆ©æ¨£æœ¬: {analysis.get('positive_roi_count', 0)}/{len(results_df)} ({analysis.get('positive_roi_pct', 0):.1f}%)")
        
        LOG.info(f"\nğŸ“‰ é¢¨éšªæŒ‡æ¨™:")
        LOG.info(f"  å¹³å‡æœ€å¤§å›æ’¤: {analysis.get('avg_max_dd', 0):.2f}%")
        LOG.info(f"  æœ€å¤§å›æ’¤: {analysis.get('max_dd_max', 0):.2f}%")
        
        # æ‰‹çºŒè²»åˆ†æ
        if 'avg_fee_cost' in analysis:
            LOG.info(f"\nğŸ’° æ‰‹çºŒè²»åˆ†æ:")
            LOG.info(f"  å¹³å‡æ‰‹çºŒè²»æˆæœ¬: {analysis['avg_fee_cost']:,.2f} TWD")
            LOG.info(f"  æœ€å¤§æ‰‹çºŒè²»æˆæœ¬: {analysis.get('total_fee_cost_max', 0):,.2f} TWD")
            if 'avg_fee_to_profit_ratio' in analysis and not pd.isna(analysis['avg_fee_to_profit_ratio']):
                LOG.info(f"  æ‰‹çºŒè²»/åˆ©æ½¤æ¯”: {analysis['avg_fee_to_profit_ratio']:.2f}")
                if analysis['avg_fee_to_profit_ratio'] > 1.0:
                    LOG.warning("  âš ï¸  æ‰‹çºŒè²»è¶…éåˆ©æ½¤ï¼é€™æ˜¯ä¸»è¦å•é¡Œï¼")
        
        # äº¤æ˜“åˆ†æ
        if 'avg_trades' in analysis:
            LOG.info(f"\nğŸ“ˆ äº¤æ˜“åˆ†æ:")
            LOG.info(f"  å¹³å‡äº¤æ˜“æ¬¡æ•¸: {analysis['avg_trades']:.0f}")
            LOG.info(f"  å¹³å‡æ¯ç­†åˆ©æ½¤: {analysis.get('avg_profit_per_trade', 0):.2f} TWD")
        
        # ç¶²æ ¼åˆ†æ
        if 'avg_grid_fill_rate' in analysis:
            LOG.info(f"\nğŸ”² ç¶²æ ¼åˆ†æ:")
            LOG.info(f"  å¹³å‡ç¶²æ ¼æˆäº¤ç‡: {analysis['avg_grid_fill_rate']:.2%}")
            LOG.info(f"  å¹³å‡ç¶²æ ¼æˆäº¤æ¬¡æ•¸: {analysis.get('avg_grid_fills', 0):.0f}")
        
        # è¶¨å‹¢æ¨¡å¼åˆ†æ
        if 'avg_trend_entries' in analysis:
            LOG.info(f"\nğŸ“Š è¶¨å‹¢æ¨¡å¼åˆ†æ:")
            LOG.info(f"  å¹³å‡è¶¨å‹¢é€²å ´æ¬¡æ•¸: {analysis['avg_trend_entries']:.1f}")
            LOG.info(f"  å¹³å‡è¶¨å‹¢å‡ºå ´æ¬¡æ•¸: {analysis.get('avg_trend_exits', 0):.1f}")
        
        # å•é¡Œè¨ºæ–·
        LOG.info(f"\nğŸ” å•é¡Œè¨ºæ–·:")
        issues = []
        
        if analysis.get('positive_roi_pct', 0) < 10:
            issues.append("âŒ ç›ˆåˆ©æ¨£æœ¬æ¯”ä¾‹æ¥µä½ (<10%)ï¼Œç­–ç•¥å¯èƒ½ä¸é©åˆç•¶å‰å¸‚å ´ç’°å¢ƒ")
        
        if analysis.get('avg_fee_to_profit_ratio', 0) > 1.0:
            issues.append("âŒ æ‰‹çºŒè²»æˆæœ¬è¶…éåˆ©æ½¤ï¼Œéœ€è¦é™ä½äº¤æ˜“é »ç‡æˆ–ä½¿ç”¨makerè¨‚å–®")
        
        if analysis.get('avg_grid_fill_rate', 0) < 0.1:
            issues.append("âš ï¸  ç¶²æ ¼æˆäº¤ç‡éä½ (<10%)ï¼Œç¶²æ ¼é–“è·å¯èƒ½å¤ªå¤§")
        
        if analysis.get('avg_grid_fill_rate', 0) > 0.9:
            issues.append("âš ï¸  ç¶²æ ¼æˆäº¤ç‡éé«˜ (>90%)ï¼Œç¶²æ ¼é–“è·å¯èƒ½å¤ªå°ï¼Œå°è‡´é »ç¹äº¤æ˜“")
        
        if analysis.get('avg_max_dd', 0) > 20:
            issues.append("âš ï¸  å¹³å‡æœ€å¤§å›æ’¤éé«˜ (>20%)ï¼Œé¢¨éšªæ§åˆ¶éœ€è¦åŠ å¼·")
        
        if not issues:
            issues.append("âœ“ æœªç™¼ç¾æ˜é¡¯å•é¡Œï¼Œå»ºè­°é€²ä¸€æ­¥æ“´å¤§æ¨£æœ¬æ•¸é‡æˆ–èª¿æ•´åƒæ•¸ç¯„åœ")
        
        for issue in issues:
            LOG.info(f"  {issue}")
        
        # ä¿å­˜CSVå ±å‘Š
        results_df.to_csv(output_path / 'diagnosis_results.csv', index=False, encoding='utf-8-sig')
        LOG.info(f"\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜è‡³: {output_path / 'diagnosis_results.csv'}")
        
        return issues


def main():
    parser = argparse.ArgumentParser(description="ç­–ç•¥è¨ºæ–·åˆ†æå·¥å…·")
    parser.add_argument("--csv", required=True, type=Path, help="OHLC CSVæ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--config", default="config_usdttwd.yaml", type=Path, help="é…ç½®æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--init_usdt", default=10000.0, type=float, help="åˆå§‹USDTé¤˜é¡")
    parser.add_argument("--init_twd", default=300000.0, type=float, help="åˆå§‹TWDé¤˜é¡")
    parser.add_argument("--samples", default=20, type=int, help="æ¨£æœ¬æ•¸é‡")
    parser.add_argument("--output", default=".", type=Path, help="è¼¸å‡ºç›®éŒ„")
    
    args = parser.parse_args()
    
    if not args.csv.exists():
        LOG.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv}")
        return
    
    if not args.config.exists():
        LOG.error(f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {args.config}")
        return
    
    args.output.mkdir(parents=True, exist_ok=True)
    
    # é‹è¡Œè¨ºæ–·
    diagnostic = StrategyDiagnostic(
        csv_path=args.csv,
        base_config_path=args.config,
        init_usdt=args.init_usdt,
        init_twd=args.init_twd
    )
    
    results_df = diagnostic.run_diagnosis(n_samples=args.samples)
    
    if results_df.empty:
        LOG.error("è¨ºæ–·å¤±æ•—ï¼šæ²’æœ‰æˆåŠŸå®Œæˆçš„å›æ¸¬")
        return
    
    # åˆ†æçµæœ
    analysis = diagnostic.analyze_results(results_df)
    
    # ç”Ÿæˆå ±å‘Š
    issues = diagnostic.generate_report(results_df, analysis, args.output)
    
    LOG.info("\n" + "=" * 80)
    LOG.info("è¨ºæ–·å®Œæˆ")
    LOG.info("=" * 80)


if __name__ == "__main__":
    main()

