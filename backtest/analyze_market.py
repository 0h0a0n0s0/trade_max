#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚å ´ç’°å¢ƒåˆ†æå·¥å…·
åˆ†æKç·šæ•¸æ“šç‰¹å¾µï¼Œåˆ¤æ–·å¸‚å ´æ˜¯å¦é©åˆç¶²æ ¼äº¤æ˜“ç­–ç•¥
"""

import argparse
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Tuple
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

from indicators import ema, adx, atr, rsi

LOG = logging.getLogger("MarketAnalyzer")
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - [%(name)s] %(message)s",
    level=logging.INFO
)


class MarketAnalyzer:
    """å¸‚å ´ç’°å¢ƒåˆ†æå™¨"""
    
    def __init__(self, csv_path: Path):
        self.csv_path = csv_path
        self.df = None
        self.analysis = {}
        
        self._load_data()
    
    def _load_data(self):
        """è¼‰å…¥OHLCæ•¸æ“š"""
        LOG.info(f"è¼‰å…¥æ•¸æ“š: {self.csv_path.name}...")
        try:
            temp_df = pd.read_csv(self.csv_path, usecols=['ts', 'open', 'high', 'low', 'close'])
            
            # è™•ç†æ™‚é–“æˆ³
            if pd.api.types.is_numeric_dtype(temp_df['ts']):
                try:
                    tss = pd.to_datetime(temp_df['ts'], unit='ms')
                    if tss.min().year < 2000:
                        raise ValueError("ts likely in seconds, not milliseconds.")
                except (ValueError, pd.errors.OutOfBoundsDatetime):
                    LOG.warning("ç„¡æ³•è§£ææ¯«ç§’æ™‚é–“æˆ³ï¼Œå˜—è©¦ç§’...")
                    tss = pd.to_datetime(temp_df['ts'], unit='s')
                temp_df['ts'] = tss
            else:
                temp_df['ts'] = pd.to_datetime(temp_df['ts'])
            
            self.df = temp_df.set_index('ts').sort_index()
            self.df['high'] = self.df['high'].astype(float)
            self.df['low'] = self.df['low'].astype(float)
            self.df['close'] = self.df['close'].astype(float)
            if 'open' in self.df.columns:
                self.df['open'] = self.df['open'].astype(float)
            else:
                self.df['open'] = self.df['close']  # å¦‚æœæ²’æœ‰openï¼Œä½¿ç”¨close
            
            self.df.ffill(inplace=True)
            
            LOG.info(f"âœ“ æ•¸æ“šè¼‰å…¥å®Œæˆ: {len(self.df):,} æ ¹Kç·š")
            LOG.info(f"  æ™‚é–“ç¯„åœ: {self.df.index[0]} è‡³ {self.df.index[-1]}")
        except Exception as e:
            LOG.error(f"è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}", exc_info=True)
            raise
    
    def analyze_price_trend(self) -> Dict:
        """åˆ†æåƒ¹æ ¼è¶¨å‹¢"""
        LOG.info("åˆ†æåƒ¹æ ¼è¶¨å‹¢...")
        
        close = self.df['close']
        initial_price = close.iloc[0]
        final_price = close.iloc[-1]
        price_change_pct = ((final_price - initial_price) / initial_price) * 100
        
        # è¨ˆç®—EMAåˆ¤æ–·è¶¨å‹¢
        ema_fast = ema(close, span=60)
        ema_slow = ema(close, span=300)
        
        # çµ±è¨ˆEMAäº¤å‰æ¬¡æ•¸
        ema_crosses = 0
        prev_fast_above = None
        for i in range(1, len(close)):
            fast_above = ema_fast.iloc[i] > ema_slow.iloc[i]
            if prev_fast_above is not None and fast_above != prev_fast_above:
                ema_crosses += 1
            prev_fast_above = fast_above
        
        # è¨ˆç®—è¶¨å‹¢æŒçºŒæ™‚é–“
        trend_duration = []
        current_trend = None
        trend_start = 0
        for i in range(len(close)):
            is_uptrend = ema_fast.iloc[i] > ema_slow.iloc[i]
            if current_trend != is_uptrend:
                if current_trend is not None:
                    trend_duration.append(i - trend_start)
                current_trend = is_uptrend
                trend_start = i
        if current_trend is not None:
            trend_duration.append(len(close) - trend_start)
        
        avg_trend_duration = np.mean(trend_duration) if trend_duration else 0
        
        return {
            'initial_price': float(initial_price),
            'final_price': float(final_price),
            'price_change_pct': float(price_change_pct),
            'is_uptrend': price_change_pct > 0,
            'ema_crosses': ema_crosses,
            'avg_trend_duration': float(avg_trend_duration),
            'trend_type': 'ä¸Šæ¼²' if price_change_pct > 5 else ('ä¸‹è·Œ' if price_change_pct < -5 else 'éœ‡ç›ª')
        }
    
    def analyze_volatility(self) -> Dict:
        """åˆ†ææ³¢å‹•ç‡"""
        LOG.info("åˆ†ææ³¢å‹•ç‡...")
        
        close = self.df['close']
        high = self.df['high']
        low = self.df['low']
        
        # è¨ˆç®—ATR
        atr_series = atr(high, low, close, period=14)
        avg_atr = atr_series.mean()
        atr_pct = (avg_atr / close.mean()) * 100
        
        # è¨ˆç®—æ—¥å…§æ³¢å‹•
        daily_range = (high - low) / close
        avg_daily_range = daily_range.mean() * 100
        
        # è¨ˆç®—åƒ¹æ ¼æ³¢å‹•ç¯„åœ
        price_range = (close.max() - close.min()) / close.min() * 100
        
        # è¨ˆç®—é€£çºŒä¸Šæ¼²/ä¸‹è·Œå¤©æ•¸
        returns = close.pct_change()
        consecutive_up = 0
        consecutive_down = 0
        max_consecutive_up = 0
        max_consecutive_down = 0
        
        for ret in returns:
            if pd.isna(ret):
                continue
            if ret > 0:
                consecutive_up += 1
                consecutive_down = 0
                max_consecutive_up = max(max_consecutive_up, consecutive_up)
            elif ret < 0:
                consecutive_down += 1
                consecutive_up = 0
                max_consecutive_down = max(max_consecutive_down, consecutive_down)
            else:
                consecutive_up = 0
                consecutive_down = 0
        
        return {
            'avg_atr': float(avg_atr),
            'atr_pct': float(atr_pct),
            'avg_daily_range_pct': float(avg_daily_range),
            'price_range_pct': float(price_range),
            'max_consecutive_up': int(max_consecutive_up),
            'max_consecutive_down': int(max_consecutive_down),
            'volatility_level': 'é«˜' if atr_pct > 1.0 else ('ä¸­' if atr_pct > 0.5 else 'ä½')
        }
    
    def analyze_trend_strength(self) -> Dict:
        """åˆ†æè¶¨å‹¢å¼·åº¦"""
        LOG.info("åˆ†æè¶¨å‹¢å¼·åº¦...")
        
        high = self.df['high']
        low = self.df['low']
        close = self.df['close']
        
        # è¨ˆç®—ADX
        adx_series, plus_di, minus_di = adx(high, low, close, period=14)
        avg_adx = adx_series.mean()
        
        # çµ±è¨ˆå¼·è¶¨å‹¢æ™‚æ®µæ¯”ä¾‹
        strong_trend_pct = (adx_series > 25).sum() / len(adx_series) * 100
        weak_trend_pct = (adx_series < 20).sum() / len(adx_series) * 100
        
        # è¨ˆç®—RSI
        rsi_series = rsi(close, period=14)
        avg_rsi = rsi_series.mean()
        overbought_pct = (rsi_series > 70).sum() / len(rsi_series) * 100
        oversold_pct = (rsi_series < 30).sum() / len(rsi_series) * 100
        
        return {
            'avg_adx': float(avg_adx),
            'strong_trend_pct': float(strong_trend_pct),
            'weak_trend_pct': float(weak_trend_pct),
            'avg_rsi': float(avg_rsi),
            'overbought_pct': float(overbought_pct),
            'oversold_pct': float(oversold_pct),
            'market_type': 'å¼·è¶¨å‹¢' if avg_adx > 25 else ('å¼±è¶¨å‹¢' if avg_adx < 20 else 'éœ‡ç›ª')
        }
    
    def analyze_grid_suitability(self) -> Dict:
        """åˆ†æç¶²æ ¼äº¤æ˜“é©åˆåº¦"""
        LOG.info("åˆ†æç¶²æ ¼äº¤æ˜“é©åˆåº¦...")
        
        close = self.df['close']
        high = self.df['high']
        low = self.df['low']
        
        # è¨ˆç®—é©åˆç¶²æ ¼äº¤æ˜“çš„æ¢ä»¶
        atr_series = atr(high, low, close, period=14)
        adx_series, _, _ = adx(high, low, close, period=14)
        
        # ç†æƒ³ç¶²æ ¼æ¢ä»¶ï¼š
        # 1. æ³¢å‹•ç‡é©ä¸­ï¼ˆATRåœ¨0.5%-2%ä¹‹é–“ï¼‰
        atr_pct = (atr_series / close) * 100
        suitable_volatility = ((atr_pct > 0.5) & (atr_pct < 2.0)).sum() / len(atr_series) * 100
        
        # 2. å¼±è¶¨å‹¢æˆ–éœ‡ç›ªå¸‚å ´ï¼ˆADX < 25ï¼‰
        suitable_trend = (adx_series < 25).sum() / len(adx_series) * 100
        
        # 3. åƒ¹æ ¼åœ¨å€é–“å…§éœ‡ç›ªï¼ˆè¨ˆç®—åƒ¹æ ¼åœ¨å¸ƒæ—å¸¶å…§çš„æ™‚é–“ï¼‰
        from indicators import bollinger
        upper, middle, lower = bollinger(close, window=20, k=2.0)
        in_band = ((close >= lower) & (close <= upper)).sum() / len(close) * 100
        
        # ç¶œåˆè©•åˆ†
        suitability_score = (suitable_volatility * 0.4 + suitable_trend * 0.4 + in_band * 0.2)
        
        return {
            'suitable_volatility_pct': float(suitable_volatility),
            'suitable_trend_pct': float(suitable_trend),
            'price_in_band_pct': float(in_band),
            'suitability_score': float(suitability_score),
            'suitability_level': 'é©åˆ' if suitability_score > 60 else ('ä¸€èˆ¬' if suitability_score > 40 else 'ä¸é©åˆ')
        }
    
    def run_full_analysis(self) -> Dict:
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        LOG.info("=" * 80)
        LOG.info("é–‹å§‹å¸‚å ´ç’°å¢ƒåˆ†æ")
        LOG.info("=" * 80)
        
        self.analysis = {
            'data_info': {
                'total_bars': len(self.df),
                'start_date': str(self.df.index[0]),
                'end_date': str(self.df.index[-1]),
                'timeframe': '1åˆ†é˜' if (self.df.index[1] - self.df.index[0]).total_seconds() == 60 else 'æœªçŸ¥'
            },
            'price_trend': self.analyze_price_trend(),
            'volatility': self.analyze_volatility(),
            'trend_strength': self.analyze_trend_strength(),
            'grid_suitability': self.analyze_grid_suitability()
        }
        
        return self.analysis
    
    def generate_report(self, output_path: Path):
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        LOG.info("\n" + "=" * 80)
        LOG.info("å¸‚å ´ç’°å¢ƒåˆ†æå ±å‘Š")
        LOG.info("=" * 80)
        
        # æ•¸æ“šä¿¡æ¯
        data_info = self.analysis['data_info']
        LOG.info(f"\nğŸ“Š æ•¸æ“šä¿¡æ¯:")
        LOG.info(f"  ç¸½Kç·šæ•¸: {data_info['total_bars']:,}")
        LOG.info(f"  æ™‚é–“ç¯„åœ: {data_info['start_date']} è‡³ {data_info['end_date']}")
        LOG.info(f"  Kç·šé€±æœŸ: {data_info['timeframe']}")
        
        # åƒ¹æ ¼è¶¨å‹¢
        trend = self.analysis['price_trend']
        LOG.info(f"\nğŸ“ˆ åƒ¹æ ¼è¶¨å‹¢:")
        LOG.info(f"  åˆå§‹åƒ¹æ ¼: {trend['initial_price']:.3f} TWD")
        LOG.info(f"  æœ€çµ‚åƒ¹æ ¼: {trend['final_price']:.3f} TWD")
        LOG.info(f"  åƒ¹æ ¼è®ŠåŒ–: {trend['price_change_pct']:.2f}%")
        LOG.info(f"  è¶¨å‹¢é¡å‹: {trend['trend_type']}")
        LOG.info(f"  EMAäº¤å‰æ¬¡æ•¸: {trend['ema_crosses']}")
        LOG.info(f"  å¹³å‡è¶¨å‹¢æŒçºŒæ™‚é–“: {trend['avg_trend_duration']:.0f} æ ¹Kç·š")
        
        # æ³¢å‹•ç‡
        vol = self.analysis['volatility']
        LOG.info(f"\nğŸ“Š æ³¢å‹•ç‡åˆ†æ:")
        LOG.info(f"  å¹³å‡ATR: {vol['avg_atr']:.3f} TWD ({vol['atr_pct']:.2f}%)")
        LOG.info(f"  å¹³å‡æ—¥å…§æ³¢å‹•: {vol['avg_daily_range_pct']:.2f}%")
        LOG.info(f"  åƒ¹æ ¼æ³¢å‹•ç¯„åœ: {vol['price_range_pct']:.2f}%")
        LOG.info(f"  æ³¢å‹•ç‡æ°´å¹³: {vol['volatility_level']}")
        LOG.info(f"  æœ€å¤§é€£çºŒä¸Šæ¼²: {vol['max_consecutive_up']} æ ¹Kç·š")
        LOG.info(f"  æœ€å¤§é€£çºŒä¸‹è·Œ: {vol['max_consecutive_down']} æ ¹Kç·š")
        
        # è¶¨å‹¢å¼·åº¦
        strength = self.analysis['trend_strength']
        LOG.info(f"\nğŸ’ª è¶¨å‹¢å¼·åº¦:")
        LOG.info(f"  å¹³å‡ADX: {strength['avg_adx']:.2f}")
        LOG.info(f"  å¼·è¶¨å‹¢æ™‚æ®µ: {strength['strong_trend_pct']:.1f}%")
        LOG.info(f"  å¼±è¶¨å‹¢æ™‚æ®µ: {strength['weak_trend_pct']:.1f}%")
        LOG.info(f"  å¸‚å ´é¡å‹: {strength['market_type']}")
        LOG.info(f"  å¹³å‡RSI: {strength['avg_rsi']:.1f}")
        LOG.info(f"  è¶…è²·æ™‚æ®µ: {strength['overbought_pct']:.1f}%")
        LOG.info(f"  è¶…è³£æ™‚æ®µ: {strength['oversold_pct']:.1f}%")
        
        # ç¶²æ ¼é©åˆåº¦
        suitability = self.analysis['grid_suitability']
        LOG.info(f"\nğŸ¯ ç¶²æ ¼äº¤æ˜“é©åˆåº¦:")
        LOG.info(f"  é©åˆæ³¢å‹•ç‡æ™‚æ®µ: {suitability['suitable_volatility_pct']:.1f}%")
        LOG.info(f"  é©åˆè¶¨å‹¢æ™‚æ®µ: {suitability['suitable_trend_pct']:.1f}%")
        LOG.info(f"  åƒ¹æ ¼åœ¨å€é–“å…§: {suitability['price_in_band_pct']:.1f}%")
        LOG.info(f"  ç¶œåˆé©åˆåº¦è©•åˆ†: {suitability['suitability_score']:.1f}/100")
        LOG.info(f"  é©åˆåº¦ç­‰ç´š: {suitability['suitability_level']}")
        
        # å»ºè­°
        LOG.info(f"\nğŸ’¡ ç­–ç•¥å»ºè­°:")
        suggestions = []
        
        if suitability['suitability_score'] < 40:
            suggestions.append("âš ï¸  å¸‚å ´ç’°å¢ƒä¸å¤ªé©åˆç¶²æ ¼äº¤æ˜“ï¼Œå»ºè­°ï¼š")
            suggestions.append("   - è€ƒæ…®ä½¿ç”¨è¶¨å‹¢è·Ÿéš¨ç­–ç•¥")
            suggestions.append("   - æˆ–ç­‰å¾…æ›´é©åˆçš„å¸‚å ´ç’°å¢ƒ")
        elif suitability['suitability_score'] < 60:
            suggestions.append("âš ï¸  å¸‚å ´ç’°å¢ƒä¸€èˆ¬é©åˆç¶²æ ¼äº¤æ˜“ï¼Œå»ºè­°ï¼š")
            suggestions.append("   - ä½¿ç”¨è¼ƒå¤§çš„ç¶²æ ¼é–“è·")
            suggestions.append("   - å•Ÿç”¨æ··åˆæ¨¡å¼ï¼ˆè¶¨å‹¢+ç¶²æ ¼ï¼‰")
        else:
            suggestions.append("âœ“ å¸‚å ´ç’°å¢ƒé©åˆç¶²æ ¼äº¤æ˜“")
        
        if vol['atr_pct'] < 0.3:
            suggestions.append("âš ï¸  æ³¢å‹•ç‡éä½ï¼Œç¶²æ ¼é–“è·æ‡‰è¨­ç½®è¼ƒå°")
        elif vol['atr_pct'] > 2.0:
            suggestions.append("âš ï¸  æ³¢å‹•ç‡éé«˜ï¼Œç¶²æ ¼é–“è·æ‡‰è¨­ç½®è¼ƒå¤§ï¼Œä¸¦åŠ å¼·é¢¨éšªæ§åˆ¶")
        
        if strength['avg_adx'] > 30:
            suggestions.append("âš ï¸  å¼·è¶¨å‹¢å¸‚å ´ï¼Œå»ºè­°å•Ÿç”¨æ··åˆæ¨¡å¼ï¼Œåœ¨å¼·è¶¨å‹¢æ™‚ä½¿ç”¨è¶¨å‹¢è·Ÿéš¨")
        
        if not suggestions:
            suggestions.append("âœ“ æœªç™¼ç¾æ˜é¡¯å•é¡Œ")
        
        for suggestion in suggestions:
            LOG.info(f"  {suggestion}")
        
        # ä¿å­˜å ±å‘Š
        import json
        report_path = output_path / 'market_analysis_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis, f, indent=2, ensure_ascii=False, default=str)
        LOG.info(f"\nğŸ’¾ è©³ç´°å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")


def main():
    parser = argparse.ArgumentParser(description="å¸‚å ´ç’°å¢ƒåˆ†æå·¥å…·")
    parser.add_argument("--csv", required=True, type=Path, help="OHLC CSVæ–‡ä»¶è·¯å¾‘")
    parser.add_argument("--output", default=".", type=Path, help="è¼¸å‡ºç›®éŒ„")
    
    args = parser.parse_args()
    
    if not args.csv.exists():
        LOG.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv}")
        return
    
    args.output.mkdir(parents=True, exist_ok=True)
    
    # é‹è¡Œåˆ†æ
    analyzer = MarketAnalyzer(args.csv)
    analyzer.run_full_analysis()
    analyzer.generate_report(args.output)
    
    LOG.info("\n" + "=" * 80)
    LOG.info("åˆ†æå®Œæˆ")
    LOG.info("=" * 80)


if __name__ == "__main__":
    main()

